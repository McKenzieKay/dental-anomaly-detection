{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install torch==1.9.1+cu102 torchvision==0.10.1+cu102 torchaudio===0.9.1 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "# !pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Python Packages\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Torch Packages\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn import init\n",
    "\n",
    "# ML Test and Validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Other\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "\n",
    "# Our functions\n",
    "from processing_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making the Segmented Teeth Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once all of the data is added this cell needs to be run just once to segement all the teeth and create the data.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run once\n",
    "xray_path = 'panaromic0/panaromic0/'\n",
    "anomaly_path = 'panaromic0_labels/panaromic0_labels/'\n",
    "segmentation_path = 'panaromic0_teeth_segmented/panaromic0_teeth_segmented/'\n",
    "output_path = 'segmented_images/'\n",
    "which_anomaly = [0, 1, 2, 3, 4, 5, 6, 8]\n",
    "\n",
    "make_data(xray_path, anomaly_path, segmentation_path, output_path, which_anomaly=which_anomaly,\n",
    "              add_rotation=True, rotation_deg=20, add_flip=True, add_noise=True, sigma_noise=0.1,\n",
    "              add_blur=True, sigma_blur=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Smote_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TeethDataLoader_wSMOTE(data.Dataset): \n",
    "    \n",
    "    def __init__(self, train_dataloader):\n",
    "        self.images, self.labels = SMOTE_Balance(train_dataloader)\n",
    "           \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = self.images[index]\n",
    "        label = self.labels[index]               # class # \n",
    "        \n",
    "        return img.float(), torch.FloatTensor([label]) # returns tensor of modified image and label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _TeethDataLoader_Simplified_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TeethDataLoader_Simplified(data.Dataset):\n",
    "    \n",
    "    def __init__(self, path_to_df, anomalies_to_include, augments_to_include):\n",
    "        \"\"\"\n",
    "        path_to_df: the path to the main data frame ex. ~/Documents/Dental/segmented_data.csv\n",
    "        anomalies_to_include: list of anomlies based on code ex. [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
    "        augments_to_include: list of augment bools to include as list of 1s and Os \n",
    "                             ex. [1, 1, 1, 1] == [rotation, flip, noise, blur]\n",
    "                             ex. [1, 1, 0, 0] == [rotation, flip, no noise, no blur]\n",
    "        \"\"\"\n",
    "        # Read in data\n",
    "        df = pd.read_csv(path_to_df)\n",
    "        \n",
    "        # Filter out which anomalies\n",
    "        df = df[df['anomaly_code'].isin(anomalies_to_include)]\n",
    "        \n",
    "        # Filter out which augmentations to include\n",
    "        include_rotations = augments_to_include[0]\n",
    "        include_flips = augments_to_include[1]\n",
    "        include_noise = augments_to_include[2]\n",
    "        include_blur = augments_to_include[3]\n",
    "        \n",
    "        if(include_rotations == 0):\n",
    "            df = df[df['is_rotated'] == 0]\n",
    "        if(include_flips == 0):\n",
    "            df = df[df['is_flipped'] == 0]\n",
    "        if(include_noise == 0):\n",
    "            df = df[df['is_noise'] == 0]\n",
    "        if(include_blur == 0):\n",
    "            df = df[df['is_blur'] == 0]\n",
    "        \n",
    "        self.images, self.labels = df['file_path'].tolist(), df['anomaly_code'].tolist()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = cv2.imread(self.images[index])     # loads image from file\n",
    "        img = cv2.resize(img, (224, 224))        # resize image to 224x224\n",
    "        img = np.array(img, dtype=np.float32)    # change data type to float\n",
    "        img = (img / 255.)                       # normalize colors to be 0-1\n",
    "        img = img[:, :, (2, 1, 0)]               # reorder RGB\n",
    "        img = torchvision.transforms.ToTensor()(img)  # convert to tensor\n",
    "        label = self.labels[index]               # 1 or 0\n",
    "        \n",
    "        return img.float(), torch.FloatTensor([label]) # returns tensor of modified image and label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Old Loader_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rn the old loader is not being used.  This cell should be on the cutting block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TeethDataLoader(data.Dataset): # input is folder name where folders of teeth are stored\n",
    "                                     # requires overwrite __getitem__(), supporting fetching a data sample for a given key\n",
    "                                     # can also overwrite __len__(), which is expected to return the size of the dataset\n",
    "\n",
    "    \n",
    "    def __init__(self, path_to_df): # path below = ./training_images/\n",
    "                \n",
    "        xray_filenames = os.listdir(xray_path)\n",
    "        anomaly_filenames = os.listdir(anomaly_path)\n",
    "        segmentation_filenames = os.listdir(segmentation_path)\n",
    "\n",
    "        output_path = 'SegmentedTeethImages/'\n",
    "\n",
    "        for i in range(len(anomaly_filenames)):\n",
    "            # Create dataframe with tooth number\n",
    "            anomalies_df = anomaly_matching(anomaly_path + anomaly_filenames[i], \n",
    "                                            segmentation_path + segmentation_filenames[i], \n",
    "                                            io.imread(xray_path + xray_filenames[i]).shape, \n",
    "                                            normalized=True)\n",
    "            anomalies_df = remove_duplicates(anomalies_df)\n",
    "            #anomalies_df = anomalies_df[(anomalies_df['anomaly_category'] == 0) | (anomalies_df['anomaly_category'] == 1)]\n",
    "            \n",
    "            for index, row in anomalies_df.iterrows():\n",
    "                yolo_coord = row[['x_center', 'y_center', 'width', 'height']].to_list()\n",
    "                tooth_file = extract_image(xray_path + xray_filenames[i],\n",
    "                                           yolo_coord, \n",
    "                                           int(row['tooth_number']), \n",
    "                                           output_folder=output_path, \n",
    "                                           print_names=False)\n",
    "                self.images.append(tooth_file)\n",
    "                self.labels.append(row['anomaly_category'])\n",
    "                \n",
    "                if add_rotation:\n",
    "                    rotated_images = image_rotation(xray_path + xray_filenames[i], deg=rotation_deg,\n",
    "                                                    output_folder=output_path, print_names=False)\n",
    "                    rotated_labels = row['anomaly_category'] * len(rotated_images)\n",
    "                    self.images.extend(rotated_images)\n",
    "                    self.labels.extend(rotated_labels)\n",
    "                \n",
    "                if add_flip:\n",
    "                    flipped_images = image_flip(xray_path + xray_filenames[i], output_folder=output_path, print_names=False)\n",
    "                    flipped_labels = row['anomaly_category'] * len(flipped_images)\n",
    "                    self.images.extend(flipped_images)\n",
    "                    self.labels.extend(flipped_labels)\n",
    "                \n",
    "                if add_noise:\n",
    "                    noise_image = image_noise(xray_path + xray_filenames[i], sigma=.1,\n",
    "                                              output_folder=output_path, print_names=False)\n",
    "                    noise_label = row['anomaly_category']\n",
    "                    self.images.extend(noise_image)\n",
    "                    self.labels.extend(noise_label)\n",
    "                    \n",
    "                if add_blur:\n",
    "                    blur_image = image_gauss_blur(xray_path + xray_filenames[i], sigma=1,\n",
    "                                                  output_folder=output_path, print_names=False)\n",
    "                    blur_label = row['anomaly_category']\n",
    "                    self.images.extend(noise_image)\n",
    "                    self.labels.extend(noise_label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = cv2.imread(self.images[index])     # loads image from file\n",
    "        img = cv2.resize(img, (224, 224))        # resize image to 224x224\n",
    "        img = np.array(img, dtype=np.float32)    # change data type to float\n",
    "        img = (img / 255.)                       # normalize colors to be 0-1\n",
    "        img = img[:, :, (2, 1, 0)]               # reorder RGB\n",
    "        img = torchvision.transforms.ToTensor()(img)  # convert to tensor\n",
    "        label = self.labels[index]               # 1 or 0\n",
    "        \n",
    "        return img.float(), torch.FloatTensor([label]) # returns tensor of modified image and label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Model Classes and Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicConv(nn.Module):\n",
    "    # initialize class\n",
    "    def __init__(self, in_planes, out_planes, kernel_size, stride=1, \n",
    "                 padding=0, dilation=1, groups=1, relu=True, bn=True, bias=False):\n",
    "        super(BasicConv, self).__init__()\n",
    "        self.out_channels = out_planes\n",
    "        # def conv layer, in_planes/out_planes = size of features\n",
    "        self.conv = nn.Conv2d(in_planes, out_planes, \n",
    "                              kernel_size=kernel_size, stride=stride, \n",
    "                              padding=padding, dilation=dilation,\n",
    "                              groups=groups, bias=bias)\n",
    "        # batch normalization - normalization of the layers' inputs by re-centering and re-scaling\n",
    "        self.bn = nn.BatchNorm2d(out_planes,eps=1e-5, momentum=0.01, affine=True) if bn else None\n",
    "        # ReLu activation\n",
    "        self.relu = nn.ReLU() if relu else None\n",
    "\n",
    "    # create feed-forward network for conv layer\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)           # only 1 layer\n",
    "        if self.bn is not None:\n",
    "            x = self.bn(x)\n",
    "        if self.relu is not None:\n",
    "            x = self.relu(x)\n",
    "        return x\n",
    " \n",
    "    \n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1) # reshape to flatten tensor which is necessary in order to pass data into a linear layer\n",
    "                                     # add -1\n",
    "                                     # no flatten function in pytorch so need to create it\n",
    "\n",
    "            \n",
    "class ChannelGate(nn.Module):\n",
    "    def __init__(self, gate_channels, reduction_ratio=16, pool_types=['avg', 'max']):\n",
    "        super(ChannelGate, self).__init__()\n",
    "        self.gate_channels = gate_channels\n",
    "        self.mlp = nn.Sequential(\n",
    "            Flatten(),\n",
    "            nn.Linear(gate_channels, gate_channels // reduction_ratio),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(gate_channels // reduction_ratio, gate_channels)\n",
    "            )\n",
    "        self.pool_types = pool_types\n",
    "    def forward(self, x):\n",
    "        channel_att_sum = None\n",
    "        for pool_type in self.pool_types:\n",
    "            if pool_type=='avg':\n",
    "                avg_pool = F.avg_pool2d( x, (x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))\n",
    "                channel_att_raw = self.mlp( avg_pool )\n",
    "            elif pool_type=='max':\n",
    "                max_pool = F.max_pool2d( x, (x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))\n",
    "                channel_att_raw = self.mlp( max_pool )\n",
    "            elif pool_type=='lp':\n",
    "                lp_pool = F.lp_pool2d( x, 2, (x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))\n",
    "                channel_att_raw = self.mlp( lp_pool )\n",
    "            elif pool_type=='lse':\n",
    "                # LSE pool only\n",
    "                lse_pool = logsumexp_2d(x)\n",
    "                channel_att_raw = self.mlp( lse_pool )\n",
    "\n",
    "            if channel_att_sum is None:\n",
    "                channel_att_sum = channel_att_raw\n",
    "            else:\n",
    "                channel_att_sum = channel_att_sum + channel_att_raw\n",
    "\n",
    "        scale = F.sigmoid( channel_att_sum ).unsqueeze(2).unsqueeze(3).expand_as(x)\n",
    "        return x * scale\n",
    "\n",
    "    \n",
    "def logsumexp_2d(tensor):\n",
    "    tensor_flatten = tensor.view(tensor.size(0), tensor.size(1), -1)\n",
    "    s, _ = torch.max(tensor_flatten, dim=2, keepdim=True)\n",
    "    outputs = s + (tensor_flatten - s).exp().sum(dim=2, keepdim=True).log()\n",
    "    return outputs\n",
    "\n",
    "\n",
    "class ChannelPool(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return torch.cat( (torch.max(x,1)[0].unsqueeze(1), torch.mean(x,1).unsqueeze(1)), dim=1 )\n",
    "\n",
    "       \n",
    "class SpatialGate(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SpatialGate, self).__init__()\n",
    "        kernel_size = 7\n",
    "        self.compress = ChannelPool()\n",
    "        self.spatial = BasicConv(2, 1, kernel_size, stride=1, padding=(kernel_size-1) // 2, relu=False)\n",
    "    def forward(self, x):\n",
    "        x_compress = self.compress(x)\n",
    "        x_out = self.spatial(x_compress)\n",
    "        scale = F.sigmoid(x_out) # broadcasting\n",
    "        return x * scale\n",
    "\n",
    "       \n",
    "class CBAM(nn.Module):\n",
    "    def __init__(self, gate_channels, reduction_ratio=16, pool_types=['avg', 'max'], no_spatial=False):\n",
    "        super(CBAM, self).__init__()\n",
    "        self.ChannelGate = ChannelGate(gate_channels, reduction_ratio, pool_types)\n",
    "        self.no_spatial=no_spatial\n",
    "        if not no_spatial:\n",
    "            self.SpatialGate = SpatialGate()\n",
    "    def forward(self, x):\n",
    "        x_out = self.ChannelGate(x)\n",
    "        if not self.no_spatial:\n",
    "            x_out = self.SpatialGate(x_out)\n",
    "        return x_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"3x3 convolution with padding\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, use_cbam=False):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "        if use_cbam:\n",
    "            self.cbam = CBAM( planes, 16 )\n",
    "        else:\n",
    "            self.cbam = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        if not self.cbam is None:\n",
    "            out = self.cbam(out)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, use_cbam=False):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "        if use_cbam:\n",
    "            self.cbam = CBAM( planes * 4, 16 )\n",
    "        else:\n",
    "            self.cbam = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        if not self.cbam is None:\n",
    "            out = self.cbam(out)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers,  network_type, num_classes, att_type=None):\n",
    "        self.inplanes = 64\n",
    "        super(ResNet, self).__init__()\n",
    "\n",
    "        self.network_type = network_type\n",
    "        # different model config between ImageNet and CIFAR \n",
    "        if network_type == \"ImageNet\":\n",
    "            self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "            self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "            self.avgpool = nn.AvgPool2d(7)\n",
    "        else:\n",
    "            self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        if att_type=='BAM':\n",
    "            self.bam1 = BAM(64*block.expansion)\n",
    "            self.bam2 = BAM(128*block.expansion)\n",
    "            self.bam3 = BAM(256*block.expansion)\n",
    "        else:\n",
    "            self.bam1, self.bam2, self.bam3 = None, None, None\n",
    "\n",
    "        self.layer1 = self._make_layer(block, 64,  layers[0], att_type=att_type)\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, att_type=att_type)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2, att_type=att_type)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2, att_type=att_type)\n",
    "\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "        #self.fc = nn.Linear(512 * block.expansion, 1) # linear is output of probability distributions\n",
    "        self.softmax = torch.nn.Sigmoid()\n",
    "        init.kaiming_normal(self.fc.weight)\n",
    "        for key in self.state_dict():\n",
    "            if key.split('.')[-1]==\"weight\":\n",
    "                if \"conv\" in key:\n",
    "                    init.kaiming_normal(self.state_dict()[key], mode='fan_out')\n",
    "                if \"bn\" in key:\n",
    "                    if \"SpatialGate\" in key:\n",
    "                        self.state_dict()[key][...] = 0\n",
    "                    else:\n",
    "                        self.state_dict()[key][...] = 1\n",
    "            elif key.split(\".\")[-1]=='bias':\n",
    "                self.state_dict()[key][...] = 0\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, att_type=None):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, use_cbam=att_type=='CBAM'))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, use_cbam=att_type=='CBAM'))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        if self.network_type == \"ImageNet\":\n",
    "            x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        if not self.bam1 is None:\n",
    "            x = self.bam1(x)\n",
    "\n",
    "        x = self.layer2(x)\n",
    "        if not self.bam2 is None:\n",
    "            x = self.bam2(x)\n",
    "\n",
    "        x = self.layer3(x)\n",
    "        if not self.bam3 is None:\n",
    "            x = self.bam3(x)\n",
    "\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        if self.network_type == \"ImageNet\":\n",
    "            x = self.avgpool(x)\n",
    "        else:\n",
    "            x = F.avg_pool2d(x, 4)\n",
    "            \n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        #return F.normalize(x, dim=-1)\n",
    "        return self.softmax(x)\n",
    "    \n",
    "def ResidualNet(network_type, depth, num_classes, att_type):\n",
    "\n",
    "    assert network_type in [\"ImageNet\", \"CIFAR10\", \"CIFAR100\"], \"network type should be ImageNet or CIFAR10 / CIFAR100\"\n",
    "    assert depth in [5, 18, 34, 50, 101], 'network depth should be 18, 34, 50 or 101'\n",
    "\n",
    "    if depth == 18:\n",
    "        model = ResNet(BasicBlock, [2, 2, 2, 2], network_type, num_classes, att_type)\n",
    "        \n",
    "    elif depth == 5:\n",
    "        model = ResNet(BasicBlock, [1, 1, 2, 1], network_type, num_classes, att_type)\n",
    "\n",
    "    elif depth == 34:\n",
    "        model = ResNet(BasicBlock, [3, 4, 6, 3], network_type, num_classes, att_type)\n",
    "\n",
    "    elif depth == 50:\n",
    "        model = ResNet(Bottleneck, [3, 4, 6, 3], network_type, num_classes, att_type)\n",
    "\n",
    "    elif depth == 101:\n",
    "        model = ResNet(Bottleneck, [3, 4, 23, 3], network_type, num_classes, att_type)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Train and Valid Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0\n",
    "\n",
    "def train(train_loader, model, classes, optimizer, epoch):\n",
    "    model.train()\n",
    "    running_mse = 0\n",
    "    batch_idx = 0\n",
    "    correct, total = 0, 0\n",
    "    confusion_matrix = torch.zeros(classes, classes)\n",
    " \n",
    "    pd, gt = [], []\n",
    "    for (x, y) in tqdm(train_loader):\n",
    "        batch_idx += 1\n",
    "        x = x.to(device) # move data to GPU\n",
    "        y = y.to(device) # move data to GPU\n",
    "\n",
    "        out = model(x)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        #criterion = nn.BCELoss()                    # binary cross entropy loss\n",
    "        loss = criterion(out, y.squeeze(1).long())\n",
    "        #loss = criterion(out.squeeze(1), y.squeeze(1)) # calculate loss based on pred output vs actuals y, \n",
    "                                                       # .squeeze removes dimensions of 1\n",
    "        running_mse += loss.item() \n",
    "        optimizer.zero_grad()        # start gradient at 0\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, predicted = torch.max(out.data, 1)\n",
    "        #predicted = (out.data > 0.5).int()\n",
    "\n",
    "        for p in predicted:\n",
    "            pd.append(p)\n",
    "        for g in y.squeeze(1):\n",
    "            gt.append(g)\n",
    "\n",
    "        total += y.squeeze(1).size(0)\n",
    "        correct += (predicted == y.squeeze(1)).sum().item()\n",
    "        for t, p in zip(y.squeeze(1).view(-1), predicted.view(-1)):\n",
    "            confusion_matrix[t.long(), p.long()] += 1\n",
    "    \n",
    "    pd = torch.as_tensor(pd).numpy()\n",
    "    gt = torch.as_tensor(gt).numpy()\n",
    "\n",
    "    running_mse = running_mse / batch_idx\n",
    "    print('Epoch %d, loss = %.4f, batch_idx= %d' % (epoch, running_mse, batch_idx))\n",
    "    print('Epoch: %d Accuracy of the Train Images: %f' %(epoch, 100 * correct / total))\n",
    "    print('Confusion Matrix', np.round(confusion_matrix.cpu().numpy(), 2))\n",
    "    print('Classification Report', classification_report(gt, pd))\n",
    "    \n",
    "\n",
    "def valid(valid_loader, model, classes, epoch):\n",
    "    global best_accuracy\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    running_mse = 0\n",
    "    confusion_matrix = torch.zeros(classes, classes)\n",
    "    pd, gt = [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in tqdm(valid_loader):\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            out = model(x) # add .to(device) ???\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            #criterion = nn.BCELoss()\n",
    "            loss = criterion(out, y.squeeze(1).long())\n",
    "            #loss = criterion(out.squeeze(1), y.squeeze(1))\n",
    "            running_mse += loss.item()\n",
    "            _, predicted = torch.max(out.data, 1)\n",
    "            #predicted = (out.data > 0.5).int()\n",
    "\n",
    "            for p in predicted:\n",
    "                pd.append(p)\n",
    "            for g in y.squeeze(1):\n",
    "                gt.append(g)\n",
    "\n",
    "            total += y.squeeze(1).size(0)\n",
    "            correct += (predicted == y.squeeze(1)).sum().item()\n",
    "            for t, p in zip(y.squeeze(1).view(-1), predicted.view(-1)):\n",
    "                confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "    if best_accuracy < 100 * (correct/total):\n",
    "        best_accuracy = 100 * (correct/total)\n",
    "        \n",
    "    pd = torch.as_tensor(pd).numpy()\n",
    "    gt = torch.as_tensor(gt).numpy()\n",
    "      \n",
    "    print('Epoch: %d Accuracy of the Valid Images: %f' %(epoch, 100 * correct / total))\n",
    "    print('Confusion Matrix', np.round(confusion_matrix.cpu().numpy(), 2))\n",
    "    print('Classification Report', classification_report(gt, pd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if GPU available and assign it\n",
    "torch.cuda.is_available()\n",
    "device = torch.device('cuda', 1)\n",
    "# device = torch.device('cpu') # this switches to CPU for debugging\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Variables for the Models\n",
    "batch_size = 64\n",
    "epochs = 2\n",
    "path_to_df = 'segmented_data.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Model 1_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies_to_include = [0, 1, 2, 3, 4, 5, 6, 7]\n",
    "augments_to_include = [0, 0, 0, 0]\n",
    "\n",
    "num_classes_1 = len(anomalies_to_include)\n",
    "\n",
    "model_1 = ResidualNet('ImageNet', 5, num_classes_1, 'CBAM')\n",
    "model_1.to(device) # sends model to GPU\n",
    "optimizer = optim.Adam(model_1.parameters(), lr=0.00003)\n",
    "\n",
    "dataset_1 = TeethDataLoader_Simplified(path_to_df, anomalies_to_include, augments_to_include)\n",
    "\n",
    "# generate shuffled sequence of numbers based on how many images, split train/test\n",
    "train_idx_1, valid_idx_1 = train_test_split(np.arange(len(dataset_1.labels)), test_size=0.2, shuffle=True, stratify=dataset_1.labels)\n",
    "\n",
    "# Samples elements randomly from a given list of indices, without replacement\n",
    "train_sampler_1 = torch.utils.data.SubsetRandomSampler(train_idx_1)\n",
    "valid_sampler_1 = torch.utils.data.SubsetRandomSampler(valid_idx_1)\n",
    "\n",
    "# loads images associated with ids/samples from above\n",
    "train_loader_1 = torch.utils.data.DataLoader(dataset_1, batch_size=batch_size, sampler=train_sampler_1)\n",
    "valid_loader_1 = torch.utils.data.DataLoader(dataset_1, batch_size=batch_size, sampler=valid_sampler_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Model 1 with Augments_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies_to_include = [0, 1, 2, 3, 4, 5, 6, 7]\n",
    "augments_to_include = [1, 1, 1, 1]\n",
    "\n",
    "num_classes_1_aug = len(anomalies_to_include)\n",
    "\n",
    "model_1_aug = ResidualNet('ImageNet', 5, num_classes_1_aug, 'CBAM')\n",
    "model_1_aug.to(device) # sends model to GPU\n",
    "optimizer = optim.Adam(model_1_aug.parameters(), lr=0.00003)\n",
    "\n",
    "dataset_1_aug = TeethDataLoader_Simplified(path_to_df, anomalies_to_include, augments_to_include)\n",
    "\n",
    "# generate shuffled sequence of numbers based on how many images, split train/test\n",
    "train_idx_1_aug, valid_idx_1_aug = train_test_split(np.arange(len(dataset_1_aug.labels)), test_size=0.2, shuffle=True, stratify=dataset_1_aug.labels)\n",
    "\n",
    "# Samples elements randomly from a given list of indices, without replacement\n",
    "train_sampler_1_aug = torch.utils.data.SubsetRandomSampler(train_idx_1_aug)\n",
    "valid_sampler_1_aug = torch.utils.data.SubsetRandomSampler(valid_idx_1_aug)\n",
    "\n",
    "# loads images associated with ids/samples from above\n",
    "train_loader_1_aug = torch.utils.data.DataLoader(dataset_1_aug, batch_size=batch_size, sampler=train_sampler_1_aug)\n",
    "valid_loader_1_aug = torch.utils.data.DataLoader(dataset_1_aug, batch_size=batch_size, sampler=valid_sampler_1_aug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Model 1 with SMOTE_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1_SMOTE = deepcopy(model_1)\n",
    "dataset_smote_1 = TeethDataLoader_wSMOTE(train_loader_1)\n",
    "train_loader_smote_1 = torch.utils.data.DataLoader(dataset_smote_1, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Model 2_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies_to_include = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
    "augments_to_include = [0, 0, 0, 0]\n",
    "num_classes_2 = len(anomalies_to_include)\n",
    "\n",
    "model_2 = ResidualNet('ImageNet', 5, num_classes_2, 'CBAM')\n",
    "model_2.to(device) # sends model to GPU\n",
    "optimizer = optim.Adam(model_2.parameters(), lr=0.00003)\n",
    "\n",
    "dataset_2 = TeethDataLoader_Simplified(path_to_df, anomalies_to_include, augments_to_include)\n",
    "\n",
    "# generate shuffled sequence of numbers based on how many images, split train/test\n",
    "train_idx_2, valid_idx_2 = train_test_split(np.arange(len(dataset_2.labels)), test_size=0.2, shuffle=True, stratify=dataset_2.labels)\n",
    "\n",
    "# Samples elements randomly from a given list of indices, without replacement\n",
    "train_sampler_2 = torch.utils.data.SubsetRandomSampler(train_idx_2)\n",
    "valid_sampler_2 = torch.utils.data.SubsetRandomSampler(valid_idx_2)\n",
    "\n",
    "# loads images associated with ids/samples from above\n",
    "train_loader_2 = torch.utils.data.DataLoader(dataset_2, batch_size=batch_size, sampler=train_sampler_2)\n",
    "valid_loader_2 = torch.utils.data.DataLoader(dataset_2, batch_size=batch_size, sampler=valid_sampler_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Model 2 with Augments_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies_to_include = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
    "augments_to_include = [1, 1, 1, 1]\n",
    "\n",
    "num_classes_2_aug = len(anomalies_to_include)\n",
    "\n",
    "model_2_aug = ResidualNet('ImageNet', 5, num_classes_2_aug, 'CBAM')\n",
    "model_2_aug.to(device) # sends model to GPU\n",
    "optimizer = optim.Adam(model_2_aug.parameters(), lr=0.00003)\n",
    "\n",
    "dataset_2_aug = TeethDataLoader_Simplified(path_to_df, anomalies_to_include, augments_to_include)\n",
    "\n",
    "# generate shuffled sequence of numbers based on how many images, split train/test\n",
    "train_idx_2_aug, valid_idx_2_aug = train_test_split(np.arange(len(dataset_2_aug.labels)), test_size=0.2, shuffle=True, stratify=dataset_2_aug.labels)\n",
    "\n",
    "# Samples elements randomly from a given list of indices, without replacement\n",
    "train_sampler_2_aug = torch.utils.data.SubsetRandomSampler(train_idx_2_aug)\n",
    "valid_sampler_2_aug = torch.utils.data.SubsetRandomSampler(valid_idx_2_aug)\n",
    "\n",
    "# loads images associated with ids/samples from above\n",
    "train_loader_2_aug = torch.utils.data.DataLoader(dataset_2_aug, batch_size=batch_size, sampler=train_sampler_2_aug)\n",
    "valid_loader_2_aug = torch.utils.data.DataLoader(dataset_2_aug, batch_size=batch_size, sampler=valid_sampler_2_aug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Model 2 with SMOTE_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2_SMOTE = deepcopy(model_2)\n",
    "dataset_smote_2 = TeethDataLoader_wSMOTE(train_loader_2)\n",
    "train_loader_smote_2 = torch.utils.data.DataLoader(dataset_smote_2, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Model 1_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dataset_1.labels))\n",
    "print(len(dataset.images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 8):\n",
    "    print(i, \":\", dataset_1.labels.count(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(dataset_1.labels)\n",
    "plt.xlabel('class')\n",
    "plt.ylabel('count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Model 2_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dataset_2.labels))\n",
    "print(len(dataset_2.images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(0, 9):\n",
    "    print(i, \":\", dataset2.labels.count(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist(dataset2.labels)\n",
    "plt.xlabel('class')\n",
    "plt.ylabel('count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Model 1_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, epochs+1):\n",
    "    train(train_loader_1, model_1, num_classes_1, optimizer, epoch)\n",
    "    valid(valid_loader_1, model_1, num_classes_1, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'model_1.pth'\n",
    "torch.save(model_1.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Model 1 with Augments_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, epochs+1):\n",
    "    train(train_loader_1_aug, model_1_aug, num_classes_1_aug, optimizer, epoch)\n",
    "    valid(valid_loader_1_aug, model_1_aug, num_classes_1_aug, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'model_1_aug.pth'\n",
    "torch.save(model_1_aug.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Model 1 with Smote_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, epochs+1):\n",
    "    train(train_loader_smote_1, model_1_SMOTE, num_classes_1, optimizer, epoch)\n",
    "    valid(valid_loader_1, model_1_SMOTE, num_classes_1, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'model_1_SMOTE.pth'\n",
    "torch.save(model_1_SMOTE.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Model 2_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(1, epochs+1):\n",
    "    train(train_loader_2, model_2, num_classes_2, optimizer, epoch)\n",
    "    valid(valid_loader_2, model_2, num_classes_2, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'model_2.pth'\n",
    "torch.save(model_2.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Model 2 with Augments_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, epochs+1):\n",
    "    train(train_loader_2_aug, model_2_aug, num_classes_2_aug, optimizer, epoch)\n",
    "    valid(valid_loader_2_aug, model_2_aug, num_classes_2_aug, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'model_2_aug.pth'\n",
    "torch.save(model_2_aug.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Smote with Model 2_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, epochs+1):\n",
    "    train(train_loader_smote_2, model_2_SMOTE, num_classes_2, optimizer, epoch)\n",
    "    valid(valid_loader_2, model_2_SMOTE, num_classes_2, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'model_2_SMOTE.pth'\n",
    "torch.save(model_2_SMOTE.state_dict(), PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
