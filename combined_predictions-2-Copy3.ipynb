{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fe8f3aa",
   "metadata": {},
   "source": [
    "# Ensemble Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5afc77",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45ec6735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from statistics import mean\n",
    "\n",
    "# Torch imports\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from torch.nn import init\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "\n",
    "# Sklearn imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix\n",
    "\n",
    "# Custom functions\n",
    "from processing_functions_2 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c7544c",
   "metadata": {},
   "source": [
    "## GPU Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0243aee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if GPU available and assign it\n",
    "torch.cuda.is_available()\n",
    "device = torch.device('cuda', 1)\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44113ca",
   "metadata": {},
   "source": [
    "## Modeling Setup\n",
    "\n",
    "### MultiLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20f066b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models as models\n",
    "\n",
    "def model_multi_label_arch(pretrained, requires_grad):\n",
    "    model = models.resnet50(progress=True, pretrained=pretrained)\n",
    "    # to freeze the hidden layers\n",
    "    if requires_grad == False:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "    # to train the hidden layers\n",
    "    elif requires_grad == True:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = True\n",
    "    # make the classification layer learnable\n",
    "    model.fc = nn.Linear(2048, 8)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6ecb43",
   "metadata": {},
   "source": [
    "### MultiClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "734cbdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicConv(nn.Module):\n",
    "    # initialize class\n",
    "    def __init__(self, in_planes, out_planes, kernel_size, stride=1, \n",
    "                 padding=0, dilation=1, groups=1, relu=True, bn=True, bias=False):\n",
    "        super(BasicConv, self).__init__()\n",
    "        self.out_channels = out_planes\n",
    "        # def conv layer, in_planes/out_planes = size of features\n",
    "        self.conv = nn.Conv2d(in_planes, out_planes, \n",
    "                              kernel_size=kernel_size, stride=stride, \n",
    "                              padding=padding, dilation=dilation,\n",
    "                              groups=groups, bias=bias)\n",
    "        # batch normalization - normalization of the layers' inputs by re-centering and re-scaling\n",
    "        self.bn = nn.BatchNorm2d(out_planes,eps=1e-5, momentum=0.01, affine=True) if bn else None\n",
    "        # ReLu activation\n",
    "        self.relu = nn.ReLU() if relu else None\n",
    "\n",
    "    # create feed-forward network for conv layer\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)           # only 1 layer\n",
    "        if self.bn is not None:\n",
    "            x = self.bn(x)\n",
    "        if self.relu is not None:\n",
    "            x = self.relu(x)\n",
    "        return x\n",
    " \n",
    "    \n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1) # reshape to flatten tensor which is necessary in order to pass data into a linear layer\n",
    "                                     # add -1\n",
    "                                     # no flatten function in pytorch so need to create it\n",
    "\n",
    "            \n",
    "class ChannelGate(nn.Module):\n",
    "    def __init__(self, gate_channels, reduction_ratio=16, pool_types=['avg', 'max']):\n",
    "        super(ChannelGate, self).__init__()\n",
    "        self.gate_channels = gate_channels\n",
    "        self.mlp = nn.Sequential(\n",
    "            Flatten(),\n",
    "            nn.Linear(gate_channels, gate_channels // reduction_ratio),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(gate_channels // reduction_ratio, gate_channels)\n",
    "            )\n",
    "        self.pool_types = pool_types\n",
    "        \n",
    "    def forward(self, x):\n",
    "        channel_att_sum = None\n",
    "        for pool_type in self.pool_types:\n",
    "            if pool_type=='avg':\n",
    "                avg_pool = F.avg_pool2d( x, (x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))\n",
    "                channel_att_raw = self.mlp( avg_pool )\n",
    "            elif pool_type=='max':\n",
    "                max_pool = F.max_pool2d( x, (x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))\n",
    "                channel_att_raw = self.mlp( max_pool )\n",
    "            elif pool_type=='lp':\n",
    "                lp_pool = F.lp_pool2d( x, 2, (x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))\n",
    "                channel_att_raw = self.mlp( lp_pool )\n",
    "            elif pool_type=='lse':\n",
    "                # LSE pool only\n",
    "                lse_pool = logsumexp_2d(x)\n",
    "                channel_att_raw = self.mlp( lse_pool )\n",
    "\n",
    "            if channel_att_sum is None:\n",
    "                channel_att_sum = channel_att_raw\n",
    "            else:\n",
    "                channel_att_sum = channel_att_sum + channel_att_raw\n",
    "\n",
    "        scale = F.sigmoid( channel_att_sum ).unsqueeze(2).unsqueeze(3).expand_as(x)\n",
    "        return x * scale\n",
    "\n",
    "    \n",
    "def logsumexp_2d(tensor):\n",
    "    tensor_flatten = tensor.view(tensor.size(0), tensor.size(1), -1)\n",
    "    s, _ = torch.max(tensor_flatten, dim=2, keepdim=True)\n",
    "    outputs = s + (tensor_flatten - s).exp().sum(dim=2, keepdim=True).log()\n",
    "    return outputs\n",
    "\n",
    "\n",
    "class ChannelPool(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return torch.cat( (torch.max(x,1)[0].unsqueeze(1), torch.mean(x,1).unsqueeze(1)), dim=1 )\n",
    "\n",
    "       \n",
    "class SpatialGate(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SpatialGate, self).__init__()\n",
    "        kernel_size = 7\n",
    "        self.compress = ChannelPool()\n",
    "        self.spatial = BasicConv(2, 1, kernel_size, stride=1, padding=(kernel_size-1) // 2, relu=False)\n",
    "    def forward(self, x):\n",
    "        x_compress = self.compress(x)\n",
    "        x_out = self.spatial(x_compress)\n",
    "        scale = F.sigmoid(x_out) # broadcasting\n",
    "        return x * scale\n",
    "\n",
    "       \n",
    "class CBAM(nn.Module):\n",
    "    def __init__(self, gate_channels, reduction_ratio=16, pool_types=['avg', 'max'], no_spatial=False):\n",
    "        super(CBAM, self).__init__()\n",
    "        self.ChannelGate = ChannelGate(gate_channels, reduction_ratio, pool_types)\n",
    "        self.no_spatial=no_spatial\n",
    "        if not no_spatial:\n",
    "            self.SpatialGate = SpatialGate()\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x_out = self.ChannelGate(x)\n",
    "        if not self.no_spatial:\n",
    "            x_out = self.SpatialGate(x_out)\n",
    "        return x_out\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"3x3 convolution with padding\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, use_cbam=False):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "        if use_cbam:\n",
    "            self.cbam = CBAM( planes, 16 )\n",
    "        else:\n",
    "            self.cbam = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        if not self.cbam is None:\n",
    "            out = self.cbam(out)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, use_cbam=False):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "        if use_cbam:\n",
    "            self.cbam = CBAM( planes * 4, 16 )\n",
    "        else:\n",
    "            self.cbam = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        if not self.cbam is None:\n",
    "            out = self.cbam(out)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers,  network_type, num_classes, att_type=None):\n",
    "        self.inplanes = 64\n",
    "        super(ResNet, self).__init__()\n",
    "\n",
    "        self.network_type = network_type\n",
    "        # different model config between ImageNet and CIFAR \n",
    "        if network_type == \"ImageNet\":\n",
    "            self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "            self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "            self.avgpool = nn.AvgPool2d(7)\n",
    "        else:\n",
    "            self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        if att_type=='BAM':\n",
    "            self.bam1 = BAM(64*block.expansion)\n",
    "            self.bam2 = BAM(128*block.expansion)\n",
    "            self.bam3 = BAM(256*block.expansion)\n",
    "        else:\n",
    "            self.bam1, self.bam2, self.bam3 = None, None, None\n",
    "\n",
    "        self.layer1 = self._make_layer(block, 64,  layers[0], att_type=att_type)\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, att_type=att_type)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2, att_type=att_type)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2, att_type=att_type)\n",
    "\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "        #self.fc = nn.Linear(512 * block.expansion, 1) # linear is output of probability distributions\n",
    "        self.softmax = torch.nn.Sigmoid()\n",
    "        init.kaiming_normal(self.fc.weight)\n",
    "        for key in self.state_dict():\n",
    "            if key.split('.')[-1]==\"weight\":\n",
    "                if \"conv\" in key:\n",
    "                    init.kaiming_normal(self.state_dict()[key], mode='fan_out')\n",
    "                if \"bn\" in key:\n",
    "                    if \"SpatialGate\" in key:\n",
    "                        self.state_dict()[key][...] = 0\n",
    "                    else:\n",
    "                        self.state_dict()[key][...] = 1\n",
    "            elif key.split(\".\")[-1]=='bias':\n",
    "                self.state_dict()[key][...] = 0\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, att_type=None):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, use_cbam=att_type=='CBAM'))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, use_cbam=att_type=='CBAM'))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        if self.network_type == \"ImageNet\":\n",
    "            x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        if not self.bam1 is None:\n",
    "            x = self.bam1(x)\n",
    "\n",
    "        x = self.layer2(x)\n",
    "        if not self.bam2 is None:\n",
    "            x = self.bam2(x)\n",
    "\n",
    "        x = self.layer3(x)\n",
    "        if not self.bam3 is None:\n",
    "            x = self.bam3(x)\n",
    "\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        if self.network_type == \"ImageNet\":\n",
    "            x = self.avgpool(x)\n",
    "        else:\n",
    "            x = F.avg_pool2d(x, 4)\n",
    "            \n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        #return F.normalize(x, dim=-1)\n",
    "        return self.softmax(x)\n",
    "    \n",
    "def ResidualNet(network_type, depth, num_classes, att_type):\n",
    "\n",
    "    assert network_type in [\"ImageNet\", \"CIFAR10\", \"CIFAR100\"], \"network type should be ImageNet or CIFAR10 / CIFAR100\"\n",
    "    assert depth in [5, 18, 34, 50, 101], 'network depth should be 18, 34, 50 or 101'\n",
    "\n",
    "    if depth == 18:\n",
    "        model = ResNet(BasicBlock, [2, 2, 2, 2], network_type, num_classes, att_type)\n",
    "        \n",
    "    elif depth == 5:\n",
    "        model = ResNet(BasicBlock, [1, 1, 2, 1], network_type, num_classes, att_type)\n",
    "\n",
    "    elif depth == 34:\n",
    "        model = ResNet(BasicBlock, [3, 4, 6, 3], network_type, num_classes, att_type)\n",
    "\n",
    "    elif depth == 50:\n",
    "        model = ResNet(Bottleneck, [3, 4, 6, 3], network_type, num_classes, att_type)\n",
    "\n",
    "    elif depth == 101:\n",
    "        model = ResNet(Bottleneck, [3, 4, 23, 3], network_type, num_classes, att_type)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8491ff41",
   "metadata": {},
   "source": [
    "## Load Trained Models\n",
    "TODO: update to save full model instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33bab701",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=8, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#intialize the model\n",
    "model_multi_label = model_multi_label_arch(pretrained=True, requires_grad=False).to(device)\n",
    "\n",
    "# load the model checkpoint\n",
    "checkpoint = torch.load('model_multi_class_large_with_clahe_afterdrops_v1.pth')\n",
    "# load model weights state_dict\n",
    "model_multi_label.load_state_dict(checkpoint['model_state_dict'])\n",
    "model_multi_label.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2177f940",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dental-1\\AppData\\Local\\Temp/ipykernel_17412/4190062143.py:232: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  init.kaiming_normal(self.fc.weight)\n",
      "C:\\Users\\dental-1\\AppData\\Local\\Temp/ipykernel_17412/4190062143.py:236: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  init.kaiming_normal(self.state_dict()[key], mode='fan_out')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (cbam): CBAM(\n",
       "        (ChannelGate): ChannelGate(\n",
       "          (mlp): Sequential(\n",
       "            (0): Flatten()\n",
       "            (1): Linear(in_features=64, out_features=4, bias=True)\n",
       "            (2): ReLU()\n",
       "            (3): Linear(in_features=4, out_features=64, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (SpatialGate): SpatialGate(\n",
       "          (compress): ChannelPool()\n",
       "          (spatial): BasicConv(\n",
       "            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (cbam): CBAM(\n",
       "        (ChannelGate): ChannelGate(\n",
       "          (mlp): Sequential(\n",
       "            (0): Flatten()\n",
       "            (1): Linear(in_features=64, out_features=4, bias=True)\n",
       "            (2): ReLU()\n",
       "            (3): Linear(in_features=4, out_features=64, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (SpatialGate): SpatialGate(\n",
       "          (compress): ChannelPool()\n",
       "          (spatial): BasicConv(\n",
       "            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (cbam): CBAM(\n",
       "        (ChannelGate): ChannelGate(\n",
       "          (mlp): Sequential(\n",
       "            (0): Flatten()\n",
       "            (1): Linear(in_features=64, out_features=4, bias=True)\n",
       "            (2): ReLU()\n",
       "            (3): Linear(in_features=4, out_features=64, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (SpatialGate): SpatialGate(\n",
       "          (compress): ChannelPool()\n",
       "          (spatial): BasicConv(\n",
       "            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (cbam): CBAM(\n",
       "        (ChannelGate): ChannelGate(\n",
       "          (mlp): Sequential(\n",
       "            (0): Flatten()\n",
       "            (1): Linear(in_features=128, out_features=8, bias=True)\n",
       "            (2): ReLU()\n",
       "            (3): Linear(in_features=8, out_features=128, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (SpatialGate): SpatialGate(\n",
       "          (compress): ChannelPool()\n",
       "          (spatial): BasicConv(\n",
       "            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (cbam): CBAM(\n",
       "        (ChannelGate): ChannelGate(\n",
       "          (mlp): Sequential(\n",
       "            (0): Flatten()\n",
       "            (1): Linear(in_features=128, out_features=8, bias=True)\n",
       "            (2): ReLU()\n",
       "            (3): Linear(in_features=8, out_features=128, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (SpatialGate): SpatialGate(\n",
       "          (compress): ChannelPool()\n",
       "          (spatial): BasicConv(\n",
       "            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (cbam): CBAM(\n",
       "        (ChannelGate): ChannelGate(\n",
       "          (mlp): Sequential(\n",
       "            (0): Flatten()\n",
       "            (1): Linear(in_features=128, out_features=8, bias=True)\n",
       "            (2): ReLU()\n",
       "            (3): Linear(in_features=8, out_features=128, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (SpatialGate): SpatialGate(\n",
       "          (compress): ChannelPool()\n",
       "          (spatial): BasicConv(\n",
       "            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (cbam): CBAM(\n",
       "        (ChannelGate): ChannelGate(\n",
       "          (mlp): Sequential(\n",
       "            (0): Flatten()\n",
       "            (1): Linear(in_features=128, out_features=8, bias=True)\n",
       "            (2): ReLU()\n",
       "            (3): Linear(in_features=8, out_features=128, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (SpatialGate): SpatialGate(\n",
       "          (compress): ChannelPool()\n",
       "          (spatial): BasicConv(\n",
       "            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (cbam): CBAM(\n",
       "        (ChannelGate): ChannelGate(\n",
       "          (mlp): Sequential(\n",
       "            (0): Flatten()\n",
       "            (1): Linear(in_features=256, out_features=16, bias=True)\n",
       "            (2): ReLU()\n",
       "            (3): Linear(in_features=16, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (SpatialGate): SpatialGate(\n",
       "          (compress): ChannelPool()\n",
       "          (spatial): BasicConv(\n",
       "            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (cbam): CBAM(\n",
       "        (ChannelGate): ChannelGate(\n",
       "          (mlp): Sequential(\n",
       "            (0): Flatten()\n",
       "            (1): Linear(in_features=256, out_features=16, bias=True)\n",
       "            (2): ReLU()\n",
       "            (3): Linear(in_features=16, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (SpatialGate): SpatialGate(\n",
       "          (compress): ChannelPool()\n",
       "          (spatial): BasicConv(\n",
       "            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (cbam): CBAM(\n",
       "        (ChannelGate): ChannelGate(\n",
       "          (mlp): Sequential(\n",
       "            (0): Flatten()\n",
       "            (1): Linear(in_features=256, out_features=16, bias=True)\n",
       "            (2): ReLU()\n",
       "            (3): Linear(in_features=16, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (SpatialGate): SpatialGate(\n",
       "          (compress): ChannelPool()\n",
       "          (spatial): BasicConv(\n",
       "            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (cbam): CBAM(\n",
       "        (ChannelGate): ChannelGate(\n",
       "          (mlp): Sequential(\n",
       "            (0): Flatten()\n",
       "            (1): Linear(in_features=256, out_features=16, bias=True)\n",
       "            (2): ReLU()\n",
       "            (3): Linear(in_features=16, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (SpatialGate): SpatialGate(\n",
       "          (compress): ChannelPool()\n",
       "          (spatial): BasicConv(\n",
       "            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (cbam): CBAM(\n",
       "        (ChannelGate): ChannelGate(\n",
       "          (mlp): Sequential(\n",
       "            (0): Flatten()\n",
       "            (1): Linear(in_features=256, out_features=16, bias=True)\n",
       "            (2): ReLU()\n",
       "            (3): Linear(in_features=16, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (SpatialGate): SpatialGate(\n",
       "          (compress): ChannelPool()\n",
       "          (spatial): BasicConv(\n",
       "            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (cbam): CBAM(\n",
       "        (ChannelGate): ChannelGate(\n",
       "          (mlp): Sequential(\n",
       "            (0): Flatten()\n",
       "            (1): Linear(in_features=256, out_features=16, bias=True)\n",
       "            (2): ReLU()\n",
       "            (3): Linear(in_features=16, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (SpatialGate): SpatialGate(\n",
       "          (compress): ChannelPool()\n",
       "          (spatial): BasicConv(\n",
       "            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (cbam): CBAM(\n",
       "        (ChannelGate): ChannelGate(\n",
       "          (mlp): Sequential(\n",
       "            (0): Flatten()\n",
       "            (1): Linear(in_features=512, out_features=32, bias=True)\n",
       "            (2): ReLU()\n",
       "            (3): Linear(in_features=32, out_features=512, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (SpatialGate): SpatialGate(\n",
       "          (compress): ChannelPool()\n",
       "          (spatial): BasicConv(\n",
       "            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (cbam): CBAM(\n",
       "        (ChannelGate): ChannelGate(\n",
       "          (mlp): Sequential(\n",
       "            (0): Flatten()\n",
       "            (1): Linear(in_features=512, out_features=32, bias=True)\n",
       "            (2): ReLU()\n",
       "            (3): Linear(in_features=32, out_features=512, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (SpatialGate): SpatialGate(\n",
       "          (compress): ChannelPool()\n",
       "          (spatial): BasicConv(\n",
       "            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (cbam): CBAM(\n",
       "        (ChannelGate): ChannelGate(\n",
       "          (mlp): Sequential(\n",
       "            (0): Flatten()\n",
       "            (1): Linear(in_features=512, out_features=32, bias=True)\n",
       "            (2): ReLU()\n",
       "            (3): Linear(in_features=32, out_features=512, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (SpatialGate): SpatialGate(\n",
       "          (compress): ChannelPool()\n",
       "          (spatial): BasicConv(\n",
       "            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=512, out_features=8, bias=True)\n",
       "  (softmax): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_multi_class_aug = ResidualNet('ImageNet', 34, 8, 'CBAM').to(device)\n",
    "\n",
    "# load the model checkpoint\n",
    "checkpoint = torch.load('model_1_clahe_aug_weights.pth')\n",
    "# load model weights state_dict\n",
    "model_multi_class_aug.load_state_dict(checkpoint)\n",
    "model_multi_class_aug.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e652acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dental-1\\AppData\\Local\\Temp/ipykernel_17412/4190062143.py:232: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  init.kaiming_normal(self.fc.weight)\n",
      "C:\\Users\\dental-1\\AppData\\Local\\Temp/ipykernel_17412/4190062143.py:236: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  init.kaiming_normal(self.state_dict()[key], mode='fan_out')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (cbam): CBAM(\n",
       "        (ChannelGate): ChannelGate(\n",
       "          (mlp): Sequential(\n",
       "            (0): Flatten()\n",
       "            (1): Linear(in_features=64, out_features=4, bias=True)\n",
       "            (2): ReLU()\n",
       "            (3): Linear(in_features=4, out_features=64, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (SpatialGate): SpatialGate(\n",
       "          (compress): ChannelPool()\n",
       "          (spatial): BasicConv(\n",
       "            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (cbam): CBAM(\n",
       "        (ChannelGate): ChannelGate(\n",
       "          (mlp): Sequential(\n",
       "            (0): Flatten()\n",
       "            (1): Linear(in_features=128, out_features=8, bias=True)\n",
       "            (2): ReLU()\n",
       "            (3): Linear(in_features=8, out_features=128, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (SpatialGate): SpatialGate(\n",
       "          (compress): ChannelPool()\n",
       "          (spatial): BasicConv(\n",
       "            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (cbam): CBAM(\n",
       "        (ChannelGate): ChannelGate(\n",
       "          (mlp): Sequential(\n",
       "            (0): Flatten()\n",
       "            (1): Linear(in_features=256, out_features=16, bias=True)\n",
       "            (2): ReLU()\n",
       "            (3): Linear(in_features=16, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (SpatialGate): SpatialGate(\n",
       "          (compress): ChannelPool()\n",
       "          (spatial): BasicConv(\n",
       "            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (cbam): CBAM(\n",
       "        (ChannelGate): ChannelGate(\n",
       "          (mlp): Sequential(\n",
       "            (0): Flatten()\n",
       "            (1): Linear(in_features=256, out_features=16, bias=True)\n",
       "            (2): ReLU()\n",
       "            (3): Linear(in_features=16, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (SpatialGate): SpatialGate(\n",
       "          (compress): ChannelPool()\n",
       "          (spatial): BasicConv(\n",
       "            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (cbam): CBAM(\n",
       "        (ChannelGate): ChannelGate(\n",
       "          (mlp): Sequential(\n",
       "            (0): Flatten()\n",
       "            (1): Linear(in_features=512, out_features=32, bias=True)\n",
       "            (2): ReLU()\n",
       "            (3): Linear(in_features=32, out_features=512, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (SpatialGate): SpatialGate(\n",
       "          (compress): ChannelPool()\n",
       "          (spatial): BasicConv(\n",
       "            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=512, out_features=8, bias=True)\n",
       "  (softmax): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_multi_class_smote = ResidualNet('ImageNet', 5, 8, 'CBAM').to(device)\n",
    "\n",
    "# load the model checkpoint\n",
    "#checkpoint = torch.load('model_1_smote_weights_BEST.pth')\n",
    "checkpoint = torch.load('model_1_smote_weights_FINAL_7.pth')\n",
    "# checkpoint = torch.load('model_1_smote_weights_clahe_BEST_1111.pth')\n",
    "# load model weights state_dict\n",
    "model_multi_class_smote.load_state_dict(checkpoint)\n",
    "model_multi_class_smote.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77fb03fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [model_multi_class_aug, \n",
    "          model_multi_class_smote, \n",
    "          model_multi_label]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069b0c9e",
   "metadata": {},
   "source": [
    "## Showing sample predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02a592ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_key = {0: 'Filling',\n",
    "               1: 'Root canal treatment',\n",
    "               2: 'Implant',\n",
    "               3: 'Caries - low risk',\n",
    "               4: 'Caries - moderate risk',\n",
    "               5: 'Caries - high risk',\n",
    "               6: 'Periodontitis',\n",
    "               7: 'Other'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb5221cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>file_path</th>\n",
       "      <th>anomaly_codes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9473</td>\n",
       "      <td>C:/Documents/Dental_Detection/Segmented_Images...</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>12578</td>\n",
       "      <td>C:/Documents/Dental_Detection/Segmented_Images...</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>13525</td>\n",
       "      <td>C:/Documents/Dental_Detection/Segmented_Images...</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>11362</td>\n",
       "      <td>C:/Documents/Dental_Detection/Segmented_Images...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5455</td>\n",
       "      <td>C:/Documents/Dental_Detection/Segmented_Images...</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  \\\n",
       "0           0          9473   \n",
       "1           1         12578   \n",
       "2           2         13525   \n",
       "3           3         11362   \n",
       "4           4          5455   \n",
       "\n",
       "                                           file_path  anomaly_codes  \n",
       "0  C:/Documents/Dental_Detection/Segmented_Images...            7.0  \n",
       "1  C:/Documents/Dental_Detection/Segmented_Images...            7.0  \n",
       "2  C:/Documents/Dental_Detection/Segmented_Images...            7.0  \n",
       "3  C:/Documents/Dental_Detection/Segmented_Images...            0.0  \n",
       "4  C:/Documents/Dental_Detection/Segmented_Images...            7.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set = pd.read_csv('C:/Documents/Dental_Detection/data_csv/train_data_final.csv')\n",
    "training_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18de172f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0    9033\n",
       "0.0    1316\n",
       "1.0     184\n",
       "8.0     155\n",
       "6.0      74\n",
       "5.0      45\n",
       "4.0      43\n",
       "2.0      26\n",
       "3.0      13\n",
       "Name: anomaly_codes, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set['anomaly_codes'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20cf1e2",
   "metadata": {},
   "source": [
    "## Predictions with Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87ef5f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# for index, row in validation_set.iterrows():\n",
    "#     if index < 100:\n",
    "#         for model in models:\n",
    "#             # Get image\n",
    "#             image_path = row['file_path']\n",
    "#             img = cv2.imread(image_path)     # loads image from file\n",
    "#             img = cv2.resize(img, (224, 224))        # resize image to 224x224\n",
    "#             img = np.array(img, dtype=np.float32)    # change data type to float\n",
    "#             img = (img / 255.)                       # normalize colors to be 0-1\n",
    "#             img = img[:, :, (2, 1, 0)]               # reorder RGB\n",
    "#             img = torchvision.transforms.ToTensor()(img)  # convert to tensor\n",
    "#             target = row['anomaly_codes']\n",
    "\n",
    "#             image = img.to(device).unsqueeze(0)\n",
    "#             outputs = model(image)\n",
    "#             outputs = torch.sigmoid(outputs)\n",
    "#             outputs = outputs.detach().cpu()\n",
    "#             sorted_indices = np.argsort(outputs[0])\n",
    "#             best = sorted_indices[-3:].numpy()\n",
    "#             string_predicted = ''\n",
    "#             string_actual = ''\n",
    "#             for i in range(len(best)):\n",
    "#                 string_predicted += f\"{anomaly_key[best[i]]} | \"\n",
    "#             string_actual += anomaly_key[int(target)]\n",
    "#             image = image.squeeze(0)\n",
    "#             image = image.detach().cpu().numpy()\n",
    "#             image = np.transpose(image, (1, 2, 0))\n",
    "#             plt.imshow(image)\n",
    "#             plt.axis('off')\n",
    "#             plt.title(f\"PREDICTED: {string_predicted}\\nACTUAL: {string_actual}\")\n",
    "#     #         plt.savefig(f\"outputs_multi_label/inference_{counter}.jpg\")\n",
    "#             plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c22d23",
   "metadata": {},
   "source": [
    "## Measuring overall performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92a3cd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actuals = training_set['anomaly_codes']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b6e4ad",
   "metadata": {},
   "source": [
    "#### Calculate original prediction probabilities for each model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e7d1f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10889 [00:00<?, ?it/s]C:\\ProgramData\\Anaconda3\\envs\\dental_project_ajw\\lib\\site-packages\\torch\\nn\\functional.py:1805: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "100%|██████████| 10889/10889 [05:48<00:00, 31.22it/s]\n",
      "100%|██████████| 10889/10889 [03:08<00:00, 57.88it/s]\n",
      "100%|██████████| 10889/10889 [03:56<00:00, 46.11it/s]\n"
     ]
    }
   ],
   "source": [
    "all_predictions = []\n",
    "for i in range(len(models)):\n",
    "    model = models[i]\n",
    "    predictions = []\n",
    "\n",
    "    for index, row in tqdm(training_set.iterrows(), total=training_set.shape[0]):\n",
    "        image_path = row['file_path']\n",
    "        img = cv2.imread(image_path)     # loads image from file\n",
    "         # declaration of clahe\n",
    "        clahe = cv2.createCLAHE(clipLimit=12.0, tileGridSize=(8,8))\n",
    "        \n",
    "        if((i == 0) | (i == 2)):\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            img = clahe.apply(img)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "        img = cv2.resize(img, (224, 224))        # resize image to 224x224\n",
    "        img = np.array(img, dtype=np.float32)    # change data type to float\n",
    "        img = (img / 255.)                       # normalize colors to be 0-1\n",
    "        img = img[:, :, (2, 1, 0)]               # reorder RGB\n",
    "        img = torchvision.transforms.ToTensor()(img)  # convert to tensor\n",
    "        target = row['anomaly_codes']\n",
    "\n",
    "        image = img.to(device).unsqueeze(0)\n",
    "        outputs = model(image)\n",
    "        if i == 2:\n",
    "            outputs = torch.sigmoid(outputs)\n",
    "        outputs = outputs.detach().cpu()\n",
    "\n",
    "        predictions += [outputs.squeeze().tolist()]\n",
    "        df_predictions = pd.DataFrame(predictions)\n",
    "    all_predictions += [df_predictions]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42897495",
   "metadata": {},
   "source": [
    "#### calculate optimal thresholds for each class in each model that maximizes the classes' F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60a24993",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:25<00:00, 395.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: Max F1_score of 0.872 at a threshold value of 0.00020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:22<00:00, 448.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 1: Max F1_score of 0.875 at a threshold value of 0.98770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:18<00:00, 530.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 2: Max F1_score of 0.005 at a threshold value of 0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:18<00:00, 533.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 3: Max F1_score of 0.002 at a threshold value of 0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:18<00:00, 530.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 4: Max F1_score of 0.008 at a threshold value of 0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:18<00:00, 529.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 5: Max F1_score of 0.008 at a threshold value of 0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:18<00:00, 527.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 6: Max F1_score of 0.013 at a threshold value of 0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:22<00:00, 446.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 7: Max F1_score of 0.917 at a threshold value of 0.99920\n",
      "Model  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:23<00:00, 421.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: Max F1_score of 0.664 at a threshold value of 0.80230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:20<00:00, 482.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 1: Max F1_score of 0.596 at a threshold value of 0.89190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:18<00:00, 526.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 2: Max F1_score of 0.755 at a threshold value of 0.90620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:20<00:00, 492.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 3: Max F1_score of 0.629 at a threshold value of 0.97730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:22<00:00, 439.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 4: Max F1_score of 0.310 at a threshold value of 0.99940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:22<00:00, 442.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 5: Max F1_score of 0.238 at a threshold value of 0.99950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:21<00:00, 463.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 6: Max F1_score of 0.061 at a threshold value of 0.85500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:23<00:00, 424.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 7: Max F1_score of 0.907 at a threshold value of 0.00000\n",
      "Model  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:22<00:00, 451.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: Max F1_score of 0.421 at a threshold value of 0.21160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:20<00:00, 485.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 1: Max F1_score of 0.419 at a threshold value of 0.67550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:19<00:00, 525.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 2: Max F1_score of 0.458 at a threshold value of 0.42460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:18<00:00, 533.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 3: Max F1_score of 0.455 at a threshold value of 0.04860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:19<00:00, 525.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 4: Max F1_score of 0.047 at a threshold value of 0.03160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:18<00:00, 527.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 5: Max F1_score of 0.073 at a threshold value of 0.04130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:19<00:00, 525.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 6: Max F1_score of 0.092 at a threshold value of 0.05270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:23<00:00, 430.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 7: Max F1_score of 0.911 at a threshold value of 0.34300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "all_thresholds = []\n",
    "df_actuals_dummied = pd.get_dummies(df_actuals.astype(int))\n",
    "\n",
    "for i in range(len(models)):\n",
    "    print(\"Model \", i)\n",
    "    preds = all_predictions[i]\n",
    "    final_thresholds = []\n",
    "    \n",
    "    for label in range(preds.shape[1]):\n",
    "        thresholds = np.arange(0.0, 1.0, 0.0001) \n",
    "        f1_scores = []\n",
    "        for threshold in tqdm(thresholds, total = len(thresholds)):\n",
    "            y_pred = pd.Series(preds[label] > threshold).astype(int)\n",
    "            f1_scores += [f1_score(df_actuals_dummied[label], y_pred, zero_division = 0)]\n",
    "        max_f1 = max(f1_scores)\n",
    "        max_threshold = thresholds[f1_scores.index(max_f1)]\n",
    "        final_thresholds += [max_threshold]\n",
    "        print(\"Class %d: Max F1_score of %.3f at a threshold value of %.5f\" % (label, max_f1, max_threshold))\n",
    "        \n",
    "    all_thresholds += [final_thresholds]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0b453e",
   "metadata": {},
   "source": [
    "#### make final predictions based on new thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "396a39c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions_final = []\n",
    "for i in range(len(models)):\n",
    "    thresh = all_thresholds[i]\n",
    "    preds = all_predictions[i]\n",
    "    \n",
    "    preds_final = preds.copy()\n",
    "    for label in range(preds.shape[1]):\n",
    "        preds_final[label] = pd.Series(preds[label] > thresh[label]).astype(int)\n",
    "    \n",
    "    all_predictions_final += [preds_final]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b3b37ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_weighted(preds, weights, vote_threshold = 3):\n",
    "    predictions = weights[0]*preds[0] + weights[1]*preds[1] + weights[2]*preds[2]\n",
    "    predictions = pd.DataFrame(predictions > vote_threshold).astype(int)\n",
    "    \n",
    "    predictions[7] = predictions[[0, 1, 2, 3, 4, 5, 6]].sum(axis = 1)\n",
    "    predictions[7] = [0 if x > 0 else 1 for x in predictions[7]]\n",
    "    \n",
    "    return(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a4c206c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_evaluation_results(vote_results, actuals):\n",
    "    results_df = pd.DataFrame()\n",
    "    \n",
    "    for col in vote_results.columns:\n",
    "        y_pred = vote_results[col]\n",
    "        y_true = actuals[col]\n",
    "        precision = precision_score(y_true, y_pred)\n",
    "        recall = recall_score(y_true, y_pred)\n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "#         accuracy = accuracy_score(y_true, y_pred)\n",
    "        results = {'Class': col, 'Precision': precision, 'Recall': recall, 'F1': f1}\n",
    "        results_df = results_df.append(results, ignore_index = True)\n",
    "#         print(\"Class %s: PRECISION %.2f, RECALL %.2f, F1 %.2f\" % (col, precision, recall, f1))\n",
    "#         print(confusion_matrix(y_true, y_pred))   \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7080390d",
   "metadata": {},
   "source": [
    "## Ensemble 1 - Majority Vote"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9717fc67",
   "metadata": {},
   "source": [
    "#### Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e3f4501",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = ensemble_weighted(all_predictions_final, [1, 1, 1], vote_threshold = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6070d7b5",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8df97444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.769501</td>\n",
       "      <td>0.832067</td>\n",
       "      <td>0.799562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.744898</td>\n",
       "      <td>0.793478</td>\n",
       "      <td>0.768421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.646154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.080808</td>\n",
       "      <td>0.372093</td>\n",
       "      <td>0.132780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.119718</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.037260</td>\n",
       "      <td>0.418919</td>\n",
       "      <td>0.068433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.950431</td>\n",
       "      <td>0.855419</td>\n",
       "      <td>0.900425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class  Precision    Recall        F1\n",
       "0    0.0   0.769501  0.832067  0.799562\n",
       "1    1.0   0.744898  0.793478  0.768421\n",
       "2    2.0   0.538462  0.807692  0.646154\n",
       "3    3.0   0.444444  0.923077  0.600000\n",
       "4    4.0   0.080808  0.372093  0.132780\n",
       "5    5.0   0.119718  0.377778  0.181818\n",
       "6    6.0   0.037260  0.418919  0.068433\n",
       "7    7.0   0.950431  0.855419  0.900425"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = print_evaluation_results(vote_results = final, actuals = df_actuals_dummied)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151a3428",
   "metadata": {},
   "source": [
    "## Ensemble 2 - Weighted by Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40213612",
   "metadata": {},
   "source": [
    "#### create list of possible weight combos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f2d05fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight1 = np.arange(0, 2, 0.1)\n",
    "weight2 = np.arange(0, 2, 0.1)\n",
    "weight3 = np.arange(0, 2, 0.1)\n",
    "\n",
    "weights = []\n",
    "for weight_1 in weight1:\n",
    "    for weight_2 in weight2:\n",
    "        for weight_3 in weight3:\n",
    "            weights += [[weight_1, weight_2, weight_3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e36135c",
   "metadata": {},
   "source": [
    "#### Use grid search to find optimal weight combo by maximizing the mean of evaluation metrics from classes 0,1,2\n",
    "##### We know evaluation metrics are low for classes 2-6 and are less concerned about 7, so best to optimize weights based on performance of 0-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "331b73cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1s(weighted_preds, actuals):\n",
    "    f1s = []\n",
    "    for col in weighted_preds.columns[0:3]:\n",
    "        y_pred = weighted_preds[col]\n",
    "        y_true = actuals[col]\n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "        f1s += [f1]\n",
    "    return(mean(f1s))\n",
    "\n",
    "def get_recall(weighted_preds, actuals):\n",
    "    recalls = []\n",
    "    for col in weighted_preds.columns[0:3]:\n",
    "        y_pred = weighted_preds[col]\n",
    "        y_true = actuals[col]\n",
    "        recall = recall_score(y_true, y_pred)\n",
    "        recalls += [recall]\n",
    "    return(mean(recalls))\n",
    "\n",
    "def get_precision(weighted_preds, actuals):\n",
    "    precisions = []\n",
    "    for col in weighted_preds.columns[0:3]:\n",
    "        y_pred = weighted_preds[col]\n",
    "        y_true = actuals[col]\n",
    "        precision = precision_score(y_true, y_pred)\n",
    "        precisions += [precision]\n",
    "    return(mean(precisions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c369f6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(preds, actuals, weights):\n",
    "    f1_list = []\n",
    "    for test_weights in tqdm(weights, total = len(weights)):\n",
    "        weighted_preds = ensemble_weighted(preds, test_weights)\n",
    "        weighted_f1s = get_f1s(weighted_preds, actuals)\n",
    "        f1_list += [weighted_f1s]\n",
    "    return(f1_list)\n",
    "\n",
    "def grid_search_recall(preds, actuals, weights):\n",
    "    f1_list = []\n",
    "    for test_weights in tqdm(weights, total = len(weights)):\n",
    "        weighted_preds = ensemble_weighted(preds, test_weights)\n",
    "        weighted_f1s = get_recall(weighted_preds, actuals)\n",
    "        f1_list += [weighted_f1s]\n",
    "    return(f1_list)\n",
    "\n",
    "def grid_search_precision(preds, actuals, weights):\n",
    "    f1_list = []\n",
    "    for test_weights in tqdm(weights, total = len(weights)):\n",
    "        weighted_preds = ensemble_weighted(preds, test_weights)\n",
    "        weighted_f1s = get_precision(weighted_preds, actuals)\n",
    "        f1_list += [weighted_f1s]\n",
    "    return(f1_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c782c75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_model(preds, actuals, weights):\n",
    "    f1_list = grid_search(preds, actuals, weights)\n",
    "    f1_indexes = []\n",
    "    bools = f1_list == max(f1_list)\n",
    "    for indx in range(len(bools)):\n",
    "        if(bools[indx] == True):\n",
    "            f1_indexes.append(indx)\n",
    "    \n",
    "    weights = np.array(weights)\n",
    "    filtered_weights = np.array(weights[f1_indexes])\n",
    "    \n",
    "    recall_list = grid_search_recall(preds, actuals, filtered_weights)\n",
    "    recall_indexes = []\n",
    "    bools = recall_list == max(recall_list)\n",
    "    for indx in range(len(bools)):\n",
    "        if(bools[indx] == True):\n",
    "            recall_indexes.append(indx)\n",
    "    \n",
    "    filtered_weights = np.array(filtered_weights[recall_indexes])\n",
    "    \n",
    "    precision_list = grid_search_precision(preds, actuals, filtered_weights)\n",
    "    \n",
    "    final_weights = filtered_weights[precision_list.index(max(precision_list))]\n",
    "    \n",
    "    return(final_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30a471ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(weighted_preds, actuals):\n",
    "    f1s = []\n",
    "    recalls = []\n",
    "    precisions = []\n",
    "    for col in weighted_preds.columns[0:3]:\n",
    "        y_pred = weighted_preds[col]\n",
    "        y_true = actuals[col]\n",
    "        \n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "        f1s += [f1]\n",
    "        \n",
    "        recall = recall_score(y_true, y_pred)\n",
    "        recalls += [recall]\n",
    "        \n",
    "        precision = precision_score(y_true, y_pred)\n",
    "        precisions += [precision]\n",
    "        \n",
    "    return(mean(f1s), mean(recalls), mean(precisions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2bfeea2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_az(preds, actuals, weights):\n",
    "    f1_list = []\n",
    "    for test_weights in tqdm(weights, total = len(weights)):\n",
    "        weighted_preds = ensemble_weighted(preds, test_weights)\n",
    "        [avg_f1, avg_recall, avg_precision] = get_metrics(weighted_preds, actuals)\n",
    "        f1_list += [avg_f1]\n",
    "    return(f1_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5f1ab01c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8000/8000 [01:32<00:00, 86.16it/s]\n",
      "100%|██████████| 466/466 [00:05<00:00, 84.63it/s]\n",
      "100%|██████████| 466/466 [00:05<00:00, 84.81it/s]\n"
     ]
    }
   ],
   "source": [
    "final_weights_2 = grid_search_model(all_predictions_final, df_actuals_dummied, weights)\n",
    "final_final_2 = ensemble_weighted(all_predictions_final, final_weights_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "274c7f97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.2, 1.9, 0. ])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_weights_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2143328d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.897533</td>\n",
       "      <td>0.718845</td>\n",
       "      <td>0.798312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.835366</td>\n",
       "      <td>0.744565</td>\n",
       "      <td>0.787356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.754717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.628571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.255814</td>\n",
       "      <td>0.309859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.238095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.033419</td>\n",
       "      <td>0.351351</td>\n",
       "      <td>0.061033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.928678</td>\n",
       "      <td>0.898041</td>\n",
       "      <td>0.913102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class  Precision    Recall        F1\n",
       "0    0.0   0.897533  0.718845  0.798312\n",
       "1    1.0   0.835366  0.744565  0.787356\n",
       "2    2.0   0.740741  0.769231  0.754717\n",
       "3    3.0   0.500000  0.846154  0.628571\n",
       "4    4.0   0.392857  0.255814  0.309859\n",
       "5    5.0   0.185185  0.333333  0.238095\n",
       "6    6.0   0.033419  0.351351  0.061033\n",
       "7    7.0   0.928678  0.898041  0.913102"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_2 = print_evaluation_results(vote_results = final_final_2, actuals = df_actuals_dummied)\n",
    "results_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3013d878",
   "metadata": {},
   "source": [
    "## Ensemble 3 - Weighted by Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c369265",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_class(preds, actuals, weights):\n",
    "    final_weight_list = []\n",
    "    for tooth_class in range(8):\n",
    "        f1_list = []\n",
    "        for test_weights in tqdm(weights, total = len(weights)):\n",
    "            predictions = test_weights[0]*preds[0][tooth_class] + test_weights[1]*preds[1][tooth_class] + test_weights[2]*preds[2][tooth_class]\n",
    "            predictions = pd.Series(predictions > 3).astype(int)\n",
    "            weighted_f1s = f1_score(predictions, actuals[tooth_class])\n",
    "            f1_list += [weighted_f1s]\n",
    "        f1_indexes = []\n",
    "        bools = f1_list == max(f1_list)\n",
    "        for indx in range(len(bools)):\n",
    "            if(bools[indx] == True):\n",
    "                f1_indexes.append(indx)\n",
    "                \n",
    "        weights = np.array(weights)\n",
    "        filtered_weights = np.array(weights[f1_indexes])\n",
    "        \n",
    "        recall_list = []\n",
    "        for test_weights in tqdm(filtered_weights, total = len(filtered_weights)):\n",
    "            predictions = test_weights[0]*preds[0][tooth_class] + test_weights[1]*preds[1][tooth_class] + test_weights[2]*preds[2][tooth_class]\n",
    "            predictions = pd.Series(predictions > 3).astype(int)\n",
    "            weighted_recalls = recall_score(predictions, actuals[tooth_class])\n",
    "            recall_list += [weighted_recalls]\n",
    "        recall_indexes = []\n",
    "        bools = recall_list == max(recall_list)\n",
    "        for indx in range(len(bools)):\n",
    "            if(bools[indx] == True):\n",
    "                recall_indexes.append(indx)\n",
    "                \n",
    "        filtered_weights = np.array(filtered_weights[recall_indexes])\n",
    "        \n",
    "        precision_list = []\n",
    "        for test_weights in tqdm(filtered_weights, total = len(filtered_weights)):\n",
    "            predictions = test_weights[0]*preds[0][tooth_class] + test_weights[1]*preds[1][tooth_class] + test_weights[2]*preds[2][tooth_class]\n",
    "            predictions = pd.Series(predictions > 3).astype(int)\n",
    "            weighted_precision = precision_score(predictions, actuals[tooth_class])\n",
    "            precision_list += [weighted_precision]\n",
    "        \n",
    "        final_weight_list.append(filtered_weights[precision_list.index(max(precision_list))])\n",
    "    return(final_weight_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cadad77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_class(preds, weights):\n",
    "    class_predictions = []\n",
    "    predictions_df = pd.DataFrame()\n",
    "\n",
    "    for tooth_class in preds[0].columns:\n",
    "            predictions = weights.iloc[tooth_class,0]*preds[0][tooth_class] + weights.iloc[tooth_class,1]*preds[1][tooth_class] + weights.iloc[tooth_class,2]*preds[2][tooth_class]\n",
    "            predictions = pd.Series(predictions > 3).astype(int)\n",
    "\n",
    "            class_predictions.append(predictions)\n",
    "              \n",
    "    predictions_df[0] = class_predictions[0]\n",
    "    predictions_df[1] = class_predictions[1]\n",
    "    predictions_df[2] = class_predictions[2]\n",
    "    predictions_df[3] = class_predictions[3]\n",
    "    predictions_df[4] = class_predictions[4]\n",
    "    predictions_df[5] = class_predictions[5]\n",
    "    predictions_df[6] = class_predictions[6]\n",
    "    predictions_df[7] = class_predictions[7]\n",
    "        \n",
    "    \n",
    "    predictions_df[7] = predictions_df[[0, 1, 2, 3, 4, 5, 6]].sum(axis = 1)\n",
    "    predictions_df[7] = [0 if x > 0 else 1 for x in predictions_df[7]]     \n",
    "\n",
    "    return(predictions_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf066fc",
   "metadata": {},
   "source": [
    "#### Calculate optimal class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "61dd5024",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8000/8000 [00:20<00:00, 383.64it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 355.62it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 355.48it/s]\n",
      "100%|██████████| 8000/8000 [00:19<00:00, 419.91it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 400.00it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 400.00it/s]\n",
      "100%|██████████| 8000/8000 [00:18<00:00, 429.32it/s]\n",
      "100%|██████████| 516/516 [00:01<00:00, 428.89it/s]\n",
      "100%|██████████| 516/516 [00:01<00:00, 434.54it/s]\n",
      "100%|██████████| 8000/8000 [00:18<00:00, 430.67it/s]\n",
      "100%|██████████| 516/516 [00:01<00:00, 434.53it/s]\n",
      "100%|██████████| 516/516 [00:01<00:00, 427.65it/s]\n",
      "100%|██████████| 8000/8000 [00:18<00:00, 427.71it/s]\n",
      "100%|██████████| 516/516 [00:01<00:00, 427.65it/s]\n",
      "100%|██████████| 516/516 [00:01<00:00, 434.53it/s]\n",
      "100%|██████████| 8000/8000 [00:18<00:00, 428.47it/s]\n",
      "100%|██████████| 516/516 [00:01<00:00, 427.66it/s]\n",
      "100%|██████████| 516/516 [00:01<00:00, 428.87it/s]\n",
      "100%|██████████| 8000/8000 [00:18<00:00, 424.88it/s]\n",
      "100%|██████████| 516/516 [00:01<00:00, 422.19it/s]\n",
      "100%|██████████| 516/516 [00:01<00:00, 427.56it/s]\n",
      "100%|██████████| 8000/8000 [00:21<00:00, 377.96it/s]\n",
      "100%|██████████| 2222/2222 [00:05<00:00, 374.42it/s]\n",
      "100%|██████████| 2222/2222 [00:05<00:00, 373.87it/s]\n"
     ]
    }
   ],
   "source": [
    "final_weight_list = grid_search_class(all_predictions_final, df_actuals_dummied, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9d5a7ba6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1.6, 1.5, 1.5]),\n",
       " array([1.6, 1.5, 1.5]),\n",
       " array([1.2, 1.9, 0. ]),\n",
       " array([1.2, 1.9, 0. ]),\n",
       " array([1.2, 1.9, 0. ]),\n",
       " array([1.2, 1.9, 0. ]),\n",
       " array([1.2, 0. , 1.9]),\n",
       " array([0.1, 1.1, 1.9])]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_weight_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea003ca",
   "metadata": {},
   "source": [
    "#### Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e2516357",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_class_ensemble = ensemble_class(all_predictions_final, pd.DataFrame(final_weight_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8400ef7c",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1bdc421e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.881013</td>\n",
       "      <td>0.793313</td>\n",
       "      <td>0.834866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.793478</td>\n",
       "      <td>0.806630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.754717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.628571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.255814</td>\n",
       "      <td>0.309859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.238095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.081081</td>\n",
       "      <td>0.092308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.943366</td>\n",
       "      <td>0.973652</td>\n",
       "      <td>0.958270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class  Precision    Recall        F1\n",
       "0    0.0   0.881013  0.793313  0.834866\n",
       "1    1.0   0.820225  0.793478  0.806630\n",
       "2    2.0   0.740741  0.769231  0.754717\n",
       "3    3.0   0.500000  0.846154  0.628571\n",
       "4    4.0   0.392857  0.255814  0.309859\n",
       "5    5.0   0.185185  0.333333  0.238095\n",
       "6    6.0   0.107143  0.081081  0.092308\n",
       "7    7.0   0.943366  0.973652  0.958270"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_3 = print_evaluation_results(vote_results = final_class_ensemble, actuals = df_actuals_dummied)\n",
    "results_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e45966",
   "metadata": {},
   "source": [
    "## Running new weights on validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72942380",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>file_path</th>\n",
       "      <th>anomaly_codes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8309</td>\n",
       "      <td>C:/Documents/Dental_Detection/Segmented_Images...</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7245</td>\n",
       "      <td>C:/Documents/Dental_Detection/Segmented_Images...</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2786</td>\n",
       "      <td>C:/Documents/Dental_Detection/Segmented_Images...</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8441</td>\n",
       "      <td>C:/Documents/Dental_Detection/Segmented_Images...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3973</td>\n",
       "      <td>C:/Documents/Dental_Detection/Segmented_Images...</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                          file_path  \\\n",
       "0        8309  C:/Documents/Dental_Detection/Segmented_Images...   \n",
       "1        7245  C:/Documents/Dental_Detection/Segmented_Images...   \n",
       "2        2786  C:/Documents/Dental_Detection/Segmented_Images...   \n",
       "3        8441  C:/Documents/Dental_Detection/Segmented_Images...   \n",
       "4        3973  C:/Documents/Dental_Detection/Segmented_Images...   \n",
       "\n",
       "   anomaly_codes  \n",
       "0            7.0  \n",
       "1            7.0  \n",
       "2            7.0  \n",
       "3            0.0  \n",
       "4            7.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_set = pd.read_csv('C:/Documents/Dental_Detection/data_csv/valid_data_pano0_6.csv')\n",
    "validation_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bfaa21d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0    2258\n",
       "0.0     344\n",
       "1.0      51\n",
       "8.0      39\n",
       "6.0      27\n",
       "5.0      15\n",
       "4.0      14\n",
       "2.0       8\n",
       "3.0       3\n",
       "Name: anomaly_codes, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_set['anomaly_codes'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c70ee34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actuals_valid = validation_set['anomaly_codes']\n",
    "df_actuals_dummied_valid = pd.get_dummies(df_actuals_valid.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "12407110",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2759 [00:00<?, ?it/s]C:\\ProgramData\\Anaconda3\\envs\\dental_project_av\\lib\\site-packages\\torch\\nn\\functional.py:1805: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "100%|██████████| 2759/2759 [01:35<00:00, 28.99it/s]\n",
      "100%|██████████| 2759/2759 [00:36<00:00, 75.34it/s] \n",
      "100%|██████████| 2759/2759 [00:46<00:00, 59.32it/s]\n"
     ]
    }
   ],
   "source": [
    "all_predictions_valid = []\n",
    "for i in range(len(models)):\n",
    "    model = models[i]\n",
    "    predictions = []\n",
    "\n",
    "    for index, row in tqdm(validation_set.iterrows(), total = validation_set.shape[0]):\n",
    "        image_path = row['file_path']\n",
    "        img = cv2.imread(image_path)     # loads image from file\n",
    "         # declaration of clahe\n",
    "        clahe = cv2.createCLAHE(clipLimit=12.0, tileGridSize=(8,8))\n",
    "        \n",
    "        if((i == 0) | (i == 2)):\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            img = clahe.apply(img)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "        img = cv2.resize(img, (224, 224))        # resize image to 224x224\n",
    "        img = np.array(img, dtype=np.float32)    # change data type to float\n",
    "        img = (img / 255.)                       # normalize colors to be 0-1\n",
    "        img = img[:, :, (2, 1, 0)]               # reorder RGB\n",
    "        img = torchvision.transforms.ToTensor()(img)  # convert to tensor\n",
    "        target = row['anomaly_codes']\n",
    "\n",
    "        image = img.to(device).unsqueeze(0)\n",
    "        outputs = model(image)\n",
    "        if i == 2:\n",
    "            outputs = torch.sigmoid(outputs)\n",
    "        outputs = outputs.detach().cpu()\n",
    "\n",
    "        predictions += [outputs.squeeze().tolist()]\n",
    "        df_predictions = pd.DataFrame(predictions)\n",
    "    all_predictions_valid += [df_predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6773a27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:11<00:00, 884.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: Max F1_score of 0.627 at a threshold value of 0.00010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:10<00:00, 932.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 1: Max F1_score of 0.786 at a threshold value of 0.18180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:10<00:00, 955.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 2: Max F1_score of 0.006 at a threshold value of 0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:10<00:00, 955.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 3: Max F1_score of 0.002 at a threshold value of 0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:10<00:00, 952.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 4: Max F1_score of 0.010 at a threshold value of 0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:10<00:00, 953.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 5: Max F1_score of 0.011 at a threshold value of 0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:10<00:00, 949.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 6: Max F1_score of 0.019 at a threshold value of 0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:11<00:00, 870.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 7: Max F1_score of 0.908 at a threshold value of 0.99900\n",
      "Model  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:11<00:00, 851.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: Max F1_score of 0.632 at a threshold value of 0.87270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:10<00:00, 912.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 1: Max F1_score of 0.496 at a threshold value of 0.84960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:10<00:00, 948.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 2: Max F1_score of 0.207 at a threshold value of 0.37640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:10<00:00, 919.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 3: Max F1_score of 0.030 at a threshold value of 0.77910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:11<00:00, 868.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 4: Max F1_score of 0.033 at a threshold value of 0.97750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:11<00:00, 867.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 5: Max F1_score of 0.033 at a threshold value of 0.98510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:11<00:00, 892.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 6: Max F1_score of 0.020 at a threshold value of 0.00700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:11<00:00, 850.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 7: Max F1_score of 0.900 at a threshold value of 0.00000\n",
      "Model  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:11<00:00, 884.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: Max F1_score of 0.445 at a threshold value of 0.24520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:10<00:00, 915.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 1: Max F1_score of 0.369 at a threshold value of 0.50740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:10<00:00, 948.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 2: Max F1_score of 0.545 at a threshold value of 0.41010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:10<00:00, 953.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 3: Max F1_score of 0.500 at a threshold value of 0.04110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:10<00:00, 948.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 4: Max F1_score of 0.118 at a threshold value of 0.05520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:10<00:00, 949.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 5: Max F1_score of 0.214 at a threshold value of 0.04880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:10<00:00, 945.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 6: Max F1_score of 0.088 at a threshold value of 0.02810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:11<00:00, 855.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 7: Max F1_score of 0.906 at a threshold value of 0.40400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "all_thresholds = []\n",
    "\n",
    "\n",
    "for i in range(len(models)):\n",
    "    print(\"Model \", i)\n",
    "    preds = all_predictions_valid[i]\n",
    "    final_thresholds = []\n",
    "    \n",
    "    for label in range(preds.shape[1]):\n",
    "        thresholds = np.arange(0.0, 1.0, 0.0001) \n",
    "        f1_scores = []\n",
    "        for threshold in tqdm(thresholds, total = len(thresholds)):\n",
    "            y_pred = pd.Series(preds[label] > threshold).astype(int)\n",
    "            f1_scores += [f1_score(df_actuals_dummied_valid[label], y_pred, zero_division = 0)]\n",
    "        max_f1 = max(f1_scores)\n",
    "        max_threshold = thresholds[f1_scores.index(max_f1)]\n",
    "        final_thresholds += [max_threshold]\n",
    "        print(\"Class %d: Max F1_score of %.3f at a threshold value of %.5f\" % (label, max_f1, max_threshold))\n",
    "        \n",
    "    all_thresholds += [final_thresholds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bfc4e94f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0001, 0.18180000000000002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.999],\n",
       " [0.8727, 0.8496, 0.3764, 0.7791, 0.9775, 0.9851000000000001, 0.007, 0.0],\n",
       " [0.2452,\n",
       "  0.5074000000000001,\n",
       "  0.4101,\n",
       "  0.041100000000000005,\n",
       "  0.055200000000000006,\n",
       "  0.0488,\n",
       "  0.0281,\n",
       "  0.404]]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "55a99bff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0002, 0.9877, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9992000000000001],\n",
       " [0.8023,\n",
       "  0.8919,\n",
       "  0.9062,\n",
       "  0.9773000000000001,\n",
       "  0.9994000000000001,\n",
       "  0.9995,\n",
       "  0.8550000000000001,\n",
       "  0.0],\n",
       " [0.2116,\n",
       "  0.6755,\n",
       "  0.42460000000000003,\n",
       "  0.048600000000000004,\n",
       "  0.0316,\n",
       "  0.0413,\n",
       "  0.052700000000000004,\n",
       "  0.343]]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9f6ce485",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions_final_valid = []\n",
    "for i in range(len(models)):\n",
    "    thresh = all_thresholds[i]\n",
    "    preds = all_predictions_valid[i]\n",
    "    \n",
    "    preds_final = preds.copy()\n",
    "    for label in range(preds.shape[1]):\n",
    "        preds_final[label] = pd.Series(preds[label] > thresh[label]).astype(int)\n",
    "    \n",
    "    all_predictions_final_valid += [preds_final]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cb4f6c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions_final_valid_v2 = []\n",
    "for i in range(len(models)):\n",
    "    preds = all_predictions_valid[i]\n",
    "    \n",
    "    preds_final = preds.copy()\n",
    "    for label in range(preds.shape[1]):\n",
    "        preds_final[label] = pd.Series(preds[label] > .5).astype(int)\n",
    "    \n",
    "    all_predictions_final_valid_v2 += [preds_final]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5389d926",
   "metadata": {},
   "source": [
    "### Ensemble 1 Results - Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "16a41fbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.700658</td>\n",
       "      <td>0.619186</td>\n",
       "      <td>0.657407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.587302</td>\n",
       "      <td>0.725490</td>\n",
       "      <td>0.649123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.059701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.021930</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.041322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.025210</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.047431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.009834</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.019398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.852097</td>\n",
       "      <td>0.170948</td>\n",
       "      <td>0.284766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class  Precision    Recall        F1\n",
       "0    0.0   0.700658  0.619186  0.657407\n",
       "1    1.0   0.587302  0.725490  0.649123\n",
       "2    2.0   0.181818  0.500000  0.266667\n",
       "3    3.0   0.031250  0.666667  0.059701\n",
       "4    4.0   0.021930  0.357143  0.041322\n",
       "5    5.0   0.025210  0.400000  0.047431\n",
       "6    6.0   0.009834  0.703704  0.019398\n",
       "7    7.0   0.852097  0.170948  0.284766"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_valid = ensemble_weighted(all_predictions_final_valid, [1, 1, 1], vote_threshold = 1)\n",
    "results_1_valid = print_evaluation_results(vote_results = final_valid, actuals = df_actuals_dummied_valid)\n",
    "results_1_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "08cc1d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\dental_project_ajw\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\envs\\dental_project_ajw\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\envs\\dental_project_ajw\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\envs\\dental_project_ajw\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\envs\\dental_project_ajw\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.779006</td>\n",
       "      <td>0.409884</td>\n",
       "      <td>0.537143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.672269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.881673</td>\n",
       "      <td>0.980071</td>\n",
       "      <td>0.928272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class  Precision    Recall        F1\n",
       "0    0.0   0.779006  0.409884  0.537143\n",
       "1    1.0   0.588235  0.784314  0.672269\n",
       "2    2.0   0.000000  0.000000  0.000000\n",
       "3    3.0   0.000000  0.000000  0.000000\n",
       "4    4.0   0.000000  0.000000  0.000000\n",
       "5    5.0   0.000000  0.000000  0.000000\n",
       "6    6.0   0.000000  0.000000  0.000000\n",
       "7    7.0   0.881673  0.980071  0.928272"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_valid = ensemble_weighted(all_predictions_final_valid_v2, [1, 1, 1], vote_threshold = 1)\n",
    "results_1_valid = print_evaluation_results(vote_results = final_valid, actuals = df_actuals_dummied_valid)\n",
    "results_1_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd07ec3",
   "metadata": {},
   "source": [
    "### Ensemble 2 Results - Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "406ea64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8000/8000 [00:52<00:00, 153.22it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 152.38it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 152.38it/s]\n"
     ]
    }
   ],
   "source": [
    "final_weights_valid = grid_search_model(all_predictions_final_valid, df_actuals_dummied_valid, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cb8f960e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.703252</td>\n",
       "      <td>0.502907</td>\n",
       "      <td>0.586441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.505263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.214286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.054545</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.087591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.890249</td>\n",
       "      <td>0.934012</td>\n",
       "      <td>0.911606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class  Precision    Recall        F1\n",
       "0    0.0   0.703252  0.502907  0.586441\n",
       "1    1.0   0.545455  0.470588  0.505263\n",
       "2    2.0   1.000000  0.375000  0.545455\n",
       "3    3.0   1.000000  0.333333  0.500000\n",
       "4    4.0   0.333333  0.071429  0.117647\n",
       "5    5.0   0.230769  0.200000  0.214286\n",
       "6    6.0   0.054545  0.222222  0.087591\n",
       "7    7.0   0.890249  0.934012  0.911606"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_2_valid = ensemble_weighted(all_predictions_final_valid, final_weights_valid)\n",
    "results_2_valid = print_evaluation_results(vote_results = final_2_valid, actuals = df_actuals_dummied_valid)\n",
    "results_2_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e02d5293",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\dental_project_ajw\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\envs\\dental_project_ajw\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\envs\\dental_project_ajw\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\envs\\dental_project_ajw\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\envs\\dental_project_ajw\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.784810</td>\n",
       "      <td>0.360465</td>\n",
       "      <td>0.494024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.693878</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.871865</td>\n",
       "      <td>0.985385</td>\n",
       "      <td>0.925156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class  Precision    Recall        F1\n",
       "0    0.0   0.784810  0.360465  0.494024\n",
       "1    1.0   0.693878  0.666667  0.680000\n",
       "2    2.0   0.000000  0.000000  0.000000\n",
       "3    3.0   0.000000  0.000000  0.000000\n",
       "4    4.0   0.000000  0.000000  0.000000\n",
       "5    5.0   0.000000  0.000000  0.000000\n",
       "6    6.0   0.000000  0.000000  0.000000\n",
       "7    7.0   0.871865  0.985385  0.925156"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_2_valid = ensemble_weighted(all_predictions_final_valid_v2, final_weights_2)\n",
    "results_2_valid = print_evaluation_results(vote_results = final_2_valid, actuals = df_actuals_dummied_valid)\n",
    "results_2_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04556c6",
   "metadata": {},
   "source": [
    "### Ensemble 3 Results - Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7ade1564",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8000/8000 [00:12<00:00, 661.18it/s]\n",
      "100%|██████████| 154/154 [00:00<00:00, 657.07it/s]\n",
      "100%|██████████| 154/154 [00:00<00:00, 657.17it/s]\n",
      "100%|██████████| 8000/8000 [00:11<00:00, 683.83it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 640.05it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 800.00it/s]\n",
      "100%|██████████| 8000/8000 [00:11<00:00, 687.86it/s]\n",
      "100%|██████████| 516/516 [00:00<00:00, 688.03it/s]\n",
      "100%|██████████| 516/516 [00:00<00:00, 701.60it/s]\n",
      "100%|██████████| 8000/8000 [00:11<00:00, 688.09it/s]\n",
      "100%|██████████| 516/516 [00:00<00:00, 702.63it/s]\n",
      "100%|██████████| 516/516 [00:00<00:00, 684.82it/s]\n",
      "100%|██████████| 8000/8000 [00:11<00:00, 684.50it/s]\n",
      "100%|██████████| 516/516 [00:00<00:00, 702.64it/s]\n",
      "100%|██████████| 516/516 [00:00<00:00, 699.21it/s]\n",
      "100%|██████████| 8000/8000 [00:11<00:00, 683.73it/s]\n",
      "100%|██████████| 516/516 [00:00<00:00, 688.00it/s]\n",
      "100%|██████████| 516/516 [00:00<00:00, 680.70it/s]\n",
      "100%|██████████| 8000/8000 [00:11<00:00, 678.75it/s]\n",
      "100%|██████████| 2222/2222 [00:03<00:00, 686.22it/s]\n",
      "100%|██████████| 2222/2222 [00:03<00:00, 685.66it/s]\n",
      "100%|██████████| 8000/8000 [00:12<00:00, 646.35it/s]\n",
      "100%|██████████| 2222/2222 [00:03<00:00, 645.06it/s]\n",
      "100%|██████████| 2222/2222 [00:03<00:00, 644.94it/s]\n"
     ]
    }
   ],
   "source": [
    "final_weight_list = grid_search_class(all_predictions_final_valid, df_actuals_dummied_valid, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1b14a813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.700658</td>\n",
       "      <td>0.619186</td>\n",
       "      <td>0.657407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.705882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.214286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.081081</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.118812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.938884</td>\n",
       "      <td>0.923747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class  Precision    Recall        F1\n",
       "0    0.0   0.700658  0.619186  0.657407\n",
       "1    1.0   0.705882  0.705882  0.705882\n",
       "2    2.0   1.000000  0.375000  0.545455\n",
       "3    3.0   1.000000  0.333333  0.500000\n",
       "4    4.0   0.333333  0.071429  0.117647\n",
       "5    5.0   0.230769  0.200000  0.214286\n",
       "6    6.0   0.081081  0.222222  0.118812\n",
       "7    7.0   0.909091  0.938884  0.923747"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_class_ensemble_valid = ensemble_class(all_predictions_final_valid, pd.DataFrame(final_weight_list))\n",
    "results_3_valid = print_evaluation_results(vote_results = final_class_ensemble_valid, actuals = df_actuals_dummied_valid)\n",
    "results_3_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cfe95790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1.6, 1.5, 1.5]),\n",
       " array([1.6, 1.5, 1.5]),\n",
       " array([1.2, 1.9, 0. ]),\n",
       " array([1.2, 1.9, 0. ]),\n",
       " array([1.2, 1.9, 0. ]),\n",
       " array([1.2, 1.9, 0. ]),\n",
       " array([1.2, 0. , 1.9]),\n",
       " array([0.1, 1.1, 1.9])]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_weight_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec70d9b",
   "metadata": {},
   "source": [
    "# Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4c04fe6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>file_path</th>\n",
       "      <th>anomaly_codes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>C:/Documents/Dental_Detection/Segmented_Images...</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>C:/Documents/Dental_Detection/Segmented_Images...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>C:/Documents/Dental_Detection/Segmented_Images...</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>C:/Documents/Dental_Detection/Segmented_Images...</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>C:/Documents/Dental_Detection/Segmented_Images...</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                          file_path  \\\n",
       "0           0  C:/Documents/Dental_Detection/Segmented_Images...   \n",
       "1           1  C:/Documents/Dental_Detection/Segmented_Images...   \n",
       "2           2  C:/Documents/Dental_Detection/Segmented_Images...   \n",
       "3           3  C:/Documents/Dental_Detection/Segmented_Images...   \n",
       "4           4  C:/Documents/Dental_Detection/Segmented_Images...   \n",
       "\n",
       "   anomaly_codes  \n",
       "0            7.0  \n",
       "1            0.0  \n",
       "2            7.0  \n",
       "3            7.0  \n",
       "4            7.0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = pd.read_csv('C:/Documents/Dental_Detection/data_csv/test_data_final.csv')\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "614e972b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0    10668\n",
       "0.0     1923\n",
       "8.0      325\n",
       "1.0      167\n",
       "6.0      118\n",
       "5.0       74\n",
       "2.0       35\n",
       "4.0       33\n",
       "3.0       15\n",
       "Name: anomaly_codes, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set['anomaly_codes'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a0abebd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actuals_test = test_set['anomaly_codes']\n",
    "df_actuals_dummied_test = pd.get_dummies(df_actuals_test.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e4e4b16e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/13358 [00:00<?, ?it/s]C:\\ProgramData\\Anaconda3\\envs\\dental_project_av\\lib\\site-packages\\torch\\nn\\functional.py:1805: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "100%|██████████| 13358/13358 [06:06<00:00, 36.45it/s]\n",
      "100%|██████████| 13358/13358 [02:22<00:00, 94.01it/s]\n",
      "100%|██████████| 13358/13358 [02:56<00:00, 75.61it/s]\n"
     ]
    }
   ],
   "source": [
    "all_predictions_test = []\n",
    "for i in range(len(models)):\n",
    "    model = models[i]\n",
    "    predictions = []\n",
    "\n",
    "    for index, row in tqdm(test_set.iterrows(), total = test_set.shape[0]):\n",
    "        image_path = row['file_path']\n",
    "        img = cv2.imread(image_path)     # loads image from file\n",
    "         # declaration of clahe\n",
    "        clahe = cv2.createCLAHE(clipLimit=12.0, tileGridSize=(8,8))\n",
    "        \n",
    "        if((i == 0) | (i == 2)):\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            img = clahe.apply(img)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "        img = cv2.resize(img, (224, 224))        # resize image to 224x224\n",
    "        img = np.array(img, dtype=np.float32)    # change data type to float\n",
    "        img = (img / 255.)                       # normalize colors to be 0-1\n",
    "        img = img[:, :, (2, 1, 0)]               # reorder RGB\n",
    "        img = torchvision.transforms.ToTensor()(img)  # convert to tensor\n",
    "        target = row['anomaly_codes']\n",
    "\n",
    "        image = img.to(device).unsqueeze(0)\n",
    "        outputs = model(image)\n",
    "        if i == 2:\n",
    "            outputs = torch.sigmoid(outputs)\n",
    "        outputs = outputs.detach().cpu()\n",
    "\n",
    "        predictions += [outputs.squeeze().tolist()]\n",
    "        df_predictions = pd.DataFrame(predictions)\n",
    "    all_predictions_test += [df_predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "68b9477a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions_final_test = []\n",
    "for i in range(len(models)):\n",
    "    thresh = all_thresholds[i]\n",
    "    preds = all_predictions_test[i]\n",
    "    \n",
    "    preds_final = preds.copy()\n",
    "    for label in range(preds.shape[1]):\n",
    "        preds_final[label] = pd.Series(preds[label] > thresh[label]).astype(int)\n",
    "    \n",
    "    all_predictions_final_test += [preds_final]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1f0cb4",
   "metadata": {},
   "source": [
    "### Ensemble 1 Results - Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5e69cb47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.705660</td>\n",
       "      <td>0.583463</td>\n",
       "      <td>0.638770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.414938</td>\n",
       "      <td>0.598802</td>\n",
       "      <td>0.490196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.282353</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.003914</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.007605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.004505</td>\n",
       "      <td>0.151515</td>\n",
       "      <td>0.008749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.019066</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>0.035619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.009259</td>\n",
       "      <td>0.703390</td>\n",
       "      <td>0.018278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.810189</td>\n",
       "      <td>0.184852</td>\n",
       "      <td>0.301023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class  Precision    Recall        F1\n",
       "0    0.0   0.705660  0.583463  0.638770\n",
       "1    1.0   0.414938  0.598802  0.490196\n",
       "2    2.0   0.282353  0.685714  0.400000\n",
       "3    3.0   0.003914  0.133333  0.007605\n",
       "4    4.0   0.004505  0.151515  0.008749\n",
       "5    5.0   0.019066  0.270270  0.035619\n",
       "6    6.0   0.009259  0.703390  0.018278\n",
       "7    7.0   0.810189  0.184852  0.301023"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_test = ensemble_weighted(all_predictions_final_test, [1, 1, 1], vote_threshold = 1)\n",
    "results_1_test = print_evaluation_results(vote_results = final_test, actuals = df_actuals_dummied_test)\n",
    "results_1_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140b4433",
   "metadata": {},
   "source": [
    "### Ensemble 2 Results - Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "754e40c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.696649</td>\n",
       "      <td>0.410816</td>\n",
       "      <td>0.516847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.396226</td>\n",
       "      <td>0.377246</td>\n",
       "      <td>0.386503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.230769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.036697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.010590</td>\n",
       "      <td>0.059322</td>\n",
       "      <td>0.017972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.864962</td>\n",
       "      <td>0.928853</td>\n",
       "      <td>0.895769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class  Precision    Recall        F1\n",
       "0    0.0   0.696649  0.410816  0.516847\n",
       "1    1.0   0.396226  0.377246  0.386503\n",
       "2    2.0   0.352941  0.171429  0.230769\n",
       "3    3.0   0.000000  0.000000  0.000000\n",
       "4    4.0   0.000000  0.000000  0.000000\n",
       "5    5.0   0.057143  0.027027  0.036697\n",
       "6    6.0   0.010590  0.059322  0.017972\n",
       "7    7.0   0.864962  0.928853  0.895769"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_2_test = ensemble_weighted(all_predictions_final_test, final_weights_valid)\n",
    "results_2_test = print_evaluation_results(vote_results = final_2_test, actuals = df_actuals_dummied_test)\n",
    "results_2_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2354f56c",
   "metadata": {},
   "source": [
    "### Ensemble 3 Results - Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c3139bec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.705660</td>\n",
       "      <td>0.583463</td>\n",
       "      <td>0.638770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.438053</td>\n",
       "      <td>0.592814</td>\n",
       "      <td>0.503817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.230769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.036697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.007463</td>\n",
       "      <td>0.025424</td>\n",
       "      <td>0.011538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.893186</td>\n",
       "      <td>0.935133</td>\n",
       "      <td>0.913679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class  Precision    Recall        F1\n",
       "0    0.0   0.705660  0.583463  0.638770\n",
       "1    1.0   0.438053  0.592814  0.503817\n",
       "2    2.0   0.352941  0.171429  0.230769\n",
       "3    3.0   0.000000  0.000000  0.000000\n",
       "4    4.0   0.000000  0.000000  0.000000\n",
       "5    5.0   0.057143  0.027027  0.036697\n",
       "6    6.0   0.007463  0.025424  0.011538\n",
       "7    7.0   0.893186  0.935133  0.913679"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_class_ensemble_test = ensemble_class(all_predictions_final_test, pd.DataFrame(final_weight_list))\n",
    "results_3_test = print_evaluation_results(vote_results = final_class_ensemble_test, actuals = df_actuals_dummied_test)\n",
    "results_3_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
